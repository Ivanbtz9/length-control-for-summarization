{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bart large configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODULES ###\n",
    "\n",
    "import sys,os\n",
    "import tqdm\n",
    "import csv\n",
    "from datetime import datetime \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "import torch\n",
    "from torch import cuda\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# Load the ROUGE metric\n",
    "import evaluate\n",
    "\n",
    "from transformers import AutoTokenizer, BartForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_PROCS =  12\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "NUM_PROCS = os.cpu_count() \n",
    "\n",
    "print(\"NUM_PROCS = \" ,NUM_PROCS)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SEED = 42\n",
    "NUM_LOADER = 4 #config['config_machine'][\"NUM_LOADER\"] #depends of the number of thread \n",
    "\n",
    "\n",
    "# Set random seeds and deterministic pytorch for reproducibility\n",
    "torch.manual_seed(SEED) # pytorch random seed\n",
    "np.random.seed(SEED) # numpy random seed\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset CNN daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['article', 'highlights', 'id'],\n",
      "        num_rows: 14355\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['article', 'highlights', 'id'],\n",
      "        num_rows: 668\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['article', 'highlights', 'id'],\n",
      "        num_rows: 574\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Load CNN/DailyMail dataset\n",
    "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")\n",
    "\n",
    "## Comment this part for the real training time :\n",
    "\n",
    "percentage = 0.05\n",
    "\n",
    "for split in dataset: \n",
    "    dataset[split] = dataset[split].shuffle(seed=SEED).select(range(int(len(dataset[split]) * percentage)))\n",
    "\n",
    "# Check the dataset structure\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load the model and tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n",
      "<class 'transformers.models.bart.tokenization_bart_fast.BartTokenizerFast'>\n",
      "<class 'transformers.models.bart.modeling_bart.BartForConditionalGeneration'>\n",
      "BartTokenizerFast(name_or_path='facebook/bart-large', vocab_size=50265, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t50264: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "### Load model ###\n",
    "MODEL_HUB = 'facebook/bart-large'\n",
    "# Load Model and Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_HUB, clean_up_tokenization_spaces=True)\n",
    "model = BartForConditionalGeneration.from_pretrained(MODEL_HUB, forced_bos_token_id=0)\n",
    "print(tokenizer.model_max_length)\n",
    "print(type(tokenizer))\n",
    "print(type(model))\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def len_distrib(batch):\n",
    "\n",
    "#     len_articles = []\n",
    "#     len_highlights = []\n",
    "    \n",
    "#     for article, highlight in zip(batch[\"article\"], batch[\"highlights\"]):\n",
    "#         len_articles.append(len(tokenizer(article, truncation=False)[\"input_ids\"]))\n",
    "#         len_highlights.append(len(tokenizer(highlight, truncation=False)[\"input_ids\"]))\n",
    "\n",
    "\n",
    "#     source = tokenizer(batch[\"article\"],truncation=True, max_length=tokenizer.model_max_length,padding='max_length')\n",
    "#     resume = tokenizer(batch[\"highlights\"],truncation=True, max_length=tokenizer.model_max_length,padding='max_length')\n",
    "\n",
    "#     return {\n",
    "#         'input_ids': source['input_ids'], \n",
    "#         'input_mask': source['attention_mask'],\n",
    "#         'input_len': len_articles,\n",
    "#         'target_ids': resume['input_ids'], \n",
    "#         'target_mask': resume['attention_mask'],\n",
    "#         'target_len': len_highlights\n",
    "#         }\n",
    "\n",
    "def len_distrib(batch):\n",
    "\n",
    "    len_articles = []\n",
    "    len_highlights = []\n",
    "    \n",
    "    for article, highlight in zip(batch[\"article\"], batch[\"highlights\"]):\n",
    "        len_articles.append(len(tokenizer(article, truncation=False)[\"input_ids\"])-1) #Add -1 to skip the <bos> token \n",
    "        len_highlights.append(len(tokenizer(highlight, truncation=False)[\"input_ids\"])-1) #Add -1 to skip the <bos> token \n",
    "\n",
    "\n",
    "    source = tokenizer(batch[\"article\"],truncation=True, max_length=tokenizer.model_max_length)\n",
    "    resume = tokenizer(batch[\"highlights\"],truncation=True, max_length=tokenizer.model_max_length)\n",
    "\n",
    "    return {\n",
    "        'input_ids': source['input_ids'], \n",
    "        'input_mask': source['attention_mask'],\n",
    "        'input_len': len_articles,\n",
    "        'target_ids': resume['input_ids'], \n",
    "        'target_mask': resume['attention_mask'],\n",
    "        'target_len': len_highlights\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c5a8b34a90f48f7b3c76a44ed8f0c35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=12):   0%|          | 0/14355 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1105 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1153 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1210 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1498 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2187 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1585 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1142 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1702 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1717 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1448 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1070 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1888 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea1cff14e8fc444b816e040611f934a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=12):   0%|          | 0/668 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1689 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1380 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1580 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1048 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1088 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1466 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1373 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2112 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1064 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1953 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1617 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1752 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78165c990aed49b2a7b0ab1372c68aee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=12):   0%|          | 0/574 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1647 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1592 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1201 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1153 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1044 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1917 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1025 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1144 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1162 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2226 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1529 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1659 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(len_distrib,num_proc=NUM_PROCS,batched=True,batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the custom collate function\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function that add padding for each batch.\n",
    "    \"\"\"\n",
    "\n",
    "    # Pad the tokenized content\n",
    "    input_ids = [torch.tensor(item['input_ids'], dtype=torch.long) for item in batch]\n",
    "    input_ids = pad_sequence(input_ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    \n",
    "    attention_mask = [torch.tensor(item['input_mask'], dtype=torch.long) for item in batch]\n",
    "    attention_mask = pad_sequence(attention_mask, batch_first=True, padding_value=0)\n",
    "\n",
    "    decoder_input_ids  = [torch.tensor(item['target_ids'][:-1], dtype=torch.long) for item in batch]\n",
    "    decoder_input_ids = pad_sequence(decoder_input_ids, batch_first=True, padding_value=tokenizer.pad_token_id)     \n",
    "    \n",
    "    decoder_attention_mask = [torch.tensor(item['target_mask'][:-1], dtype=torch.long) for item in batch]\n",
    "    decoder_attention_mask = pad_sequence(decoder_attention_mask, batch_first=True, padding_value=0)\n",
    "    \n",
    "    input_len = torch.tensor([item['input_len'] for item in batch], dtype=torch.long)\n",
    "\n",
    "    target_len = torch.tensor([item['target_len'] for item in batch], dtype=torch.long)\n",
    "\n",
    "    # Labels should be the same as decoder_input_ids (BART-style training)\n",
    "    labels = [torch.tensor(item['target_ids'][1:], dtype=torch.long) for item in batch]\n",
    "    labels = pad_sequence(labels, batch_first=True, padding_value=tokenizer.pad_token_id)  \n",
    "    labels[labels == tokenizer.pad_token_id] = -100  # Ignore padding in loss computation\n",
    "\n",
    "    return {\n",
    "        'input_ids':input_ids,\n",
    "        'attention_mask':attention_mask,\n",
    "        'decoder_input_ids':decoder_input_ids,\n",
    "        'decoder_attention_mask':decoder_attention_mask,\n",
    "        'labels': labels,\n",
    "        'input_len': input_len,\n",
    "        'target_len': target_len\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    0,   510, 36995,  ...,   487,     4,     2],\n",
      "        [    0,  2765,   479,  ...,  1515,  2040,     2],\n",
      "        [    0,   713,    16,  ...,     1,     1,     1],\n",
      "        [    0,  2765,   479,  ...,     1,     1,     1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'decoder_input_ids': tensor([[    0,   791,     4,   104,     4, 12176,    35,  4637,   476,    12,\n",
      "         12689,   432,    64,    75,   173,    19,   270,  1738,  7148,  5084,\n",
      "           479, 50118, 20645,    12, 12689,   432,    16, 13244,   142,     9,\n",
      "          4464,    81,   797,     9, 20402,   479, 50118,  1301, 39329,  2419,\n",
      "          1855,  1168,  3843, 11004,     6,   776,  1486,   479, 50118,   448,\n",
      "          3252,  5084,    34, 18993,   758,  1519,    13,   123,     7,  1149,\n",
      "           159,   479,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1],\n",
      "        [    0, 34079,  7600,     6,  4059,     6,    21,    10,  9463,  1027,\n",
      "            11,   468, 10149,     8,   395,  1513,   479, 50118, 13584, 11419,\n",
      "           284,  1165, 29732,   272,  5069, 26695,     8,    39,  1354,  5420,\n",
      "           479, 50118,  9497,  3219,    71,  1475,    12, 17272,  5224,  3277,\n",
      "            58,    26,     7,    33,    57,   303,   479, 50118, 28586,  2040,\n",
      "          1269,  1523,   128, 12690, 34204,  4312,     7,    10,   284,    52,\n",
      "            70,   657,   108,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1],\n",
      "        [    0, 15228, 46249,  7738, 24223,  6491,    18,   979,  7380,  2311,\n",
      "         17659,     7,    39,  1150,    15,   273,   479, 50118, 22138,  3121,\n",
      "             6,    54,   128, 33437, 18091,   571, 18567,    42,  1136,  3934,\n",
      "          2584,    88,  6172,   184,   479, 50118, 31157,  5069,     9,  8805,\n",
      "          9716,    58,  1835,     7,  4127,     6,  4170,    31,  5837,   479,\n",
      "         50118,   347,  2911, 24223,  6491,   738,  1462, 50141,   261,   307,\n",
      "            25,    37, 25853,   496,  1771,  4604,   479, 50118, 29151,   202,\n",
      "            45,  1402,    99,  7958,  7844,   988, 10915,   298,  2001,    12,\n",
      "           387, 18359,  1180,   479, 50118, 31863,     6,  1489,   692,  3259,\n",
      "          9266,    21,    23,     5,  7041,     7,  2458,     5,  5032, 21236,\n",
      "             9,  3712,    12, 12984,  9737,     6,    61,    21,   656,  3456,\n",
      "           479],\n",
      "        [    0,  8773, 26095,     6,   389,     6, 30506,    15,     5, 17690,\n",
      "            15, 31571,    10,  2078,  2280,   479, 50118, 23996,  5361,  4865,\n",
      "           921,     8, 21112, 39366,   611,    25,    37, 26368,     7,   883,\n",
      "         17055,    11,  2397,   479, 50118,   894,  2641,     5,  4808,   512,\n",
      "            21,   164,   128,   506,  8831,    87,    37,    56, 11555,   108,\n",
      "         50118,   133,  1393,    21, 18361,    19,    10,   411,    12,  2151,\n",
      "          2020,     8,  2740,     7,   582,   984, 38828,   479, 50118,   894,\n",
      "            26,    24,    21,   128, 34645,  2838,   108,    53,    37,   128,\n",
      "         14656,   282,    75,    28,   608,    24,   456,  1010,   108,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1]]), 'decoder_attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'labels': tensor([[  791,     4,   104,     4, 12176,    35,  4637,   476,    12, 12689,\n",
      "           432,    64,    75,   173,    19,   270,  1738,  7148,  5084,   479,\n",
      "         50118, 20645,    12, 12689,   432,    16, 13244,   142,     9,  4464,\n",
      "            81,   797,     9, 20402,   479, 50118,  1301, 39329,  2419,  1855,\n",
      "          1168,  3843, 11004,     6,   776,  1486,   479, 50118,   448,  3252,\n",
      "          5084,    34, 18993,   758,  1519,    13,   123,     7,  1149,   159,\n",
      "           479,     2,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100],\n",
      "        [34079,  7600,     6,  4059,     6,    21,    10,  9463,  1027,    11,\n",
      "           468, 10149,     8,   395,  1513,   479, 50118, 13584, 11419,   284,\n",
      "          1165, 29732,   272,  5069, 26695,     8,    39,  1354,  5420,   479,\n",
      "         50118,  9497,  3219,    71,  1475,    12, 17272,  5224,  3277,    58,\n",
      "            26,     7,    33,    57,   303,   479, 50118, 28586,  2040,  1269,\n",
      "          1523,   128, 12690, 34204,  4312,     7,    10,   284,    52,    70,\n",
      "           657,   108,     2,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100],\n",
      "        [15228, 46249,  7738, 24223,  6491,    18,   979,  7380,  2311, 17659,\n",
      "             7,    39,  1150,    15,   273,   479, 50118, 22138,  3121,     6,\n",
      "            54,   128, 33437, 18091,   571, 18567,    42,  1136,  3934,  2584,\n",
      "            88,  6172,   184,   479, 50118, 31157,  5069,     9,  8805,  9716,\n",
      "            58,  1835,     7,  4127,     6,  4170,    31,  5837,   479, 50118,\n",
      "           347,  2911, 24223,  6491,   738,  1462, 50141,   261,   307,    25,\n",
      "            37, 25853,   496,  1771,  4604,   479, 50118, 29151,   202,    45,\n",
      "          1402,    99,  7958,  7844,   988, 10915,   298,  2001,    12,   387,\n",
      "         18359,  1180,   479, 50118, 31863,     6,  1489,   692,  3259,  9266,\n",
      "            21,    23,     5,  7041,     7,  2458,     5,  5032, 21236,     9,\n",
      "          3712,    12, 12984,  9737,     6,    61,    21,   656,  3456,   479,\n",
      "             2],\n",
      "        [ 8773, 26095,     6,   389,     6, 30506,    15,     5, 17690,    15,\n",
      "         31571,    10,  2078,  2280,   479, 50118, 23996,  5361,  4865,   921,\n",
      "             8, 21112, 39366,   611,    25,    37, 26368,     7,   883, 17055,\n",
      "            11,  2397,   479, 50118,   894,  2641,     5,  4808,   512,    21,\n",
      "           164,   128,   506,  8831,    87,    37,    56, 11555,   108, 50118,\n",
      "           133,  1393,    21, 18361,    19,    10,   411,    12,  2151,  2020,\n",
      "             8,  2740,     7,   582,   984, 38828,   479, 50118,   894,    26,\n",
      "            24,    21,   128, 34645,  2838,   108,    53,    37,   128, 14656,\n",
      "           282,    75,    28,   608,    24,   456,  1010,   108,     2,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100]]), 'input_len': tensor([1086, 1517,  873,  819]), 'target_len': tensor([ 62,  63, 111,  89])}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_params = {\n",
    "    'batch_size': 4,\n",
    "    'shuffle': True,\n",
    "    'collate_fn':collate_fn,\n",
    "    'num_workers': NUM_LOADER,\n",
    "    'pin_memory': True  #  Enables faster GPU transfers\n",
    "    }\n",
    "\n",
    "eval_params = {\n",
    "    'batch_size': 4,\n",
    "    'shuffle': False,\n",
    "    'collate_fn':collate_fn,\n",
    "    'num_workers': NUM_LOADER,\n",
    "    'pin_memory': True  #  Enables faster GPU transfers\n",
    "    }\n",
    "\n",
    "\n",
    "# This will be used down for training and validation stage for the model.\n",
    "train_loader = DataLoader(dataset[\"train\"], **train_params)\n",
    "eval_loader = DataLoader(dataset[\"validation\"], **eval_params)\n",
    "\n",
    "for batch in train_loader:\n",
    "    print(batch)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create reverse embedding for the Bart model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<class 'transformers.models.bart.modeling_bart.BartForConditionalGeneration'>, <class 'transformers.models.bart.modeling_bart.BartPreTrainedModel'>, <class 'transformers.modeling_utils.PreTrainedModel'>, <class 'torch.nn.modules.module.Module'>, <class 'transformers.modeling_utils.ModuleUtilsMixin'>, <class 'transformers.generation.utils.GenerationMixin'>, <class 'transformers.utils.hub.PushToHubMixin'>, <class 'transformers.integrations.peft.PeftAdapterMixin'>, <class 'object'>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Get all parent classes in the MRO (Method Resolution Order)\n",
    "print(BartForConditionalGeneration.__mro__)\n",
    "tokenizer.bos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "torch.Size([4, 99])\n",
      "torch.Size([4, 99])\n",
      "torch.Size([4, 99])\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.pad_token_id)\n",
    "\n",
    "mask = ~torch.isin(batch[\"decoder_input_ids\"],torch.tensor([tokenizer.pad_token_id,tokenizer.eos_token_id])) # mask with 0 where a pad_id is present\n",
    "print(mask.shape)\n",
    "\n",
    "reversed_position_input  = torch.ones(mask.shape) * mask # [1,1,1,0,0] \n",
    "\n",
    "reversed_position_input = torch.flip(torch.flip(reversed_position_input , dims=(1,)).cumsum(dim=1), dims=(1,))  \n",
    "\n",
    "print(reversed_position_input.shape)\n",
    "\n",
    "normal_round = torch.randn(batch[\"decoder_input_ids\"].shape) * mask\n",
    "\n",
    "reversed_position_input = torch.abs(torch.round(reversed_position_input  + normal_round)).to(torch.long) #add a gausian noise and converte to long\n",
    "\n",
    "print(reversed_position_input.shape)\n",
    "\n",
    "# input_decoder_position_embedding = model.model.decoder.embed_positions(reversed_position_input)\n",
    "\n",
    "# input_decoder_position_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,   791,     4,   104,     4, 12176,    35,  4637,   476,    12,\n",
       "         12689,   432,    64,    75,   173,    19,   270,  1738,  7148,  5084,\n",
       "           479, 50118, 20645,    12, 12689,   432,    16, 13244,   142,     9,\n",
       "          4464,    81,   797,     9, 20402,   479, 50118,  1301, 39329,  2419,\n",
       "          1855,  1168,  3843, 11004,     6,   776,  1486,   479, 50118,   448,\n",
       "          3252,  5084,    34, 18993,   758,  1519,    13,   123,     7,  1149,\n",
       "           159,   479,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1],\n",
       "        [    0, 34079,  7600,     6,  4059,     6,    21,    10,  9463,  1027,\n",
       "            11,   468, 10149,     8,   395,  1513,   479, 50118, 13584, 11419,\n",
       "           284,  1165, 29732,   272,  5069, 26695,     8,    39,  1354,  5420,\n",
       "           479, 50118,  9497,  3219,    71,  1475,    12, 17272,  5224,  3277,\n",
       "            58,    26,     7,    33,    57,   303,   479, 50118, 28586,  2040,\n",
       "          1269,  1523,   128, 12690, 34204,  4312,     7,    10,   284,    52,\n",
       "            70,   657,   108,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1],\n",
       "        [    0, 15228, 46249,  7738, 24223,  6491,    18,   979,  7380,  2311,\n",
       "         17659,     7,    39,  1150,    15,   273,   479, 50118, 22138,  3121,\n",
       "             6,    54,   128, 33437, 18091,   571, 18567,    42,  1136,  3934,\n",
       "          2584,    88,  6172,   184,   479, 50118, 31157,  5069,     9,  8805,\n",
       "          9716,    58,  1835,     7,  4127,     6,  4170,    31,  5837,   479,\n",
       "         50118,   347,  2911, 24223,  6491,   738,  1462, 50141,   261,   307,\n",
       "            25,    37, 25853,   496,  1771,  4604,   479, 50118, 29151,   202,\n",
       "            45,  1402,    99,  7958,  7844,   988, 10915,   298,  2001,    12,\n",
       "           387, 18359,  1180,   479, 50118, 31863,     6,  1489,   692,  3259,\n",
       "          9266,    21,    23,     5,  7041,     7,  2458,     5,  5032, 21236,\n",
       "             9,  3712,    12, 12984,  9737,     6,    61,    21,   656,  3456,\n",
       "           479],\n",
       "        [    0,  8773, 26095,     6,   389,     6, 30506,    15,     5, 17690,\n",
       "            15, 31571,    10,  2078,  2280,   479, 50118, 23996,  5361,  4865,\n",
       "           921,     8, 21112, 39366,   611,    25,    37, 26368,     7,   883,\n",
       "         17055,    11,  2397,   479, 50118,   894,  2641,     5,  4808,   512,\n",
       "            21,   164,   128,   506,  8831,    87,    37,    56, 11555,   108,\n",
       "         50118,   133,  1393,    21, 18361,    19,    10,   411,    12,  2151,\n",
       "          2020,     8,  2740,     7,   582,   984, 38828,   479, 50118,   894,\n",
       "            26,    24,    21,   128, 34645,  2838,   108,    53,    37,   128,\n",
       "         14656,   282,    75,    28,   608,    24,   456,  1010,   108,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"decoder_input_ids\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code pour les index de positions inversÃ©es "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 111])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "relu = nn.ReLU()\n",
    "\n",
    "def _reverse_position_embedding(input_ids:torch.Tensor,\n",
    "                                target_len:Optional[torch.Tensor]=None)->torch.Tensor:\n",
    "    \n",
    "    mask = ~torch.isin(input_ids,torch.tensor([tokenizer.pad_token_id])) # mask with 0 where a pad_id is present\n",
    "\n",
    "    reversed_position_input  = torch.ones(mask.shape) * mask # Put 1 where there are token index and 0 where there are pad index[1,1,1,0,0] \n",
    "    \n",
    "    if target_len is None:\n",
    "        reversed_position_input = torch.flip(torch.flip(reversed_position_input , dims=(1,)).cumsum(dim=1), dims=(1,)) \n",
    "        #[[ 54,  53, ...,0,  0],[100, 101,...,1]]\n",
    "        #print(reversed_position_input.shape)\n",
    "    else:\n",
    "        for k in range(input_ids.size(-1)):\n",
    "            reversed_position_input[:,k] = relu(target_len -k)\n",
    "\n",
    "    #Add a gaussian noise\n",
    "    normal_round = torch.randn(reversed_position_input.shape) * mask\n",
    "\n",
    "    reversed_position_input = torch.abs(torch.round(reversed_position_input  + normal_round)).to(torch.long) #add a gausian noise and converte to long\n",
    "\n",
    "\n",
    "    return reversed_position_input\n",
    "\n",
    "reversed_position_input = _reverse_position_embedding(batch[\"decoder_input_ids\"])\n",
    "print(reversed_position_input.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code pour les embeddings de position sinus/cosinus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([4, 111, 1024])\n"
     ]
    }
   ],
   "source": [
    "# # dir(model.model.decoder.layernorm_embedding)\n",
    "\n",
    "d_model = model.config.d_model\n",
    "max_len = tokenizer.model_max_length\n",
    "\n",
    "pe = torch.zeros(max_len, d_model)\n",
    "position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "div_term = torch.exp((-2*torch.arange(0, d_model)//2)/d_model * math.log(10000.0) )\n",
    "\n",
    "print(div_term.shape)\n",
    "\n",
    "print((position*div_term).shape)\n",
    "\n",
    "\n",
    "pe[:, 0::2] = torch.sin(position*div_term[0::2] )\n",
    "pe[:, 1::2] = torch.cos(position*div_term[1::2])\n",
    "\n",
    "embed_reverse_positions = nn.Embedding(num_embeddings=tokenizer.model_max_length,\n",
    "                                              embedding_dim=d_model,\n",
    "                                              padding_idx=tokenizer.pad_token_id,\n",
    "                                              _weight=pe,\n",
    "                                              _freeze=True)\n",
    "\n",
    "print(embed_reverse_positions(reversed_position_input).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BartDecoder(\n",
      "  (embed_tokens): BartScaledWordEmbedding(50265, 1024, padding_idx=1)\n",
      "  (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
      "  (layers): ModuleList(\n",
      "    (0-11): 12 x BartDecoderLayer(\n",
      "      (self_attn): BartSdpaAttention(\n",
      "        (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      )\n",
      "      (activation_fn): GELUActivation()\n",
      "      (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (encoder_attn): BartSdpaAttention(\n",
      "        (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      )\n",
      "      (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "      (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "      (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "torch.Size([4, 111, 1024])\n",
      "torch.Size([4, 111, 1024])\n",
      "torch.Size([4, 111, 1024])\n"
     ]
    }
   ],
   "source": [
    "print(model.model.decoder)\n",
    "token_embeddings = model.model.decoder.embed_tokens(batch[\"decoder_input_ids\"]) \n",
    "print(token_embeddings.shape)\n",
    "position_embeddings = model.model.decoder.embed_positions(batch[\"decoder_input_ids\"]) \n",
    "print(position_embeddings.shape)\n",
    "repilot_embeddings = embed_reverse_positions(_reverse_position_embedding(batch[\"decoder_input_ids\"]))\n",
    "print(repilot_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs_embeds = token_embeddings + position_embeddings + repilot_embeddings\n",
    "output = model(input_ids=batch[\"input_ids\"], \n",
    "               attention_mask=batch[\"attention_mask\"],\n",
    "               decoder_attention_mask=batch[\"decoder_attention_mask\"], \n",
    "               decoder_inputs_embeds=decoder_inputs_embeds,\n",
    "               labels=batch[\"labels\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "from torch import nn\n",
    "from transformers import BartForConditionalGeneration, AutoTokenizer\n",
    "\n",
    "class RepilotBartForConditionalGeneration(BartForConditionalGeneration):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.relu = nn.ReLU()\n",
    "        # Define the reversed position embedding module\n",
    "        self.embed_reverse_positions = self._create_reverse_position_embedding(config)\n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    def _create_reverse_position_embedding(config):\n",
    "        \"\"\"Creates sinusoidal reversed position embeddings.\"\"\"\n",
    "        d_model = config.d_model\n",
    "        max_len = config.max_position_embeddings  \n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(-2 * (torch.arange(0, d_model) // 2) / d_model * math.log(10000.0))\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term[0::2])\n",
    "        pe[:, 1::2] = torch.cos(position * div_term[1::2])\n",
    "\n",
    "        embedding = nn.Embedding(num_embeddings=tokenizer.model_max_length,\n",
    "                                              embedding_dim=d_model,\n",
    "                                              padding_idx=tokenizer.pad_token_id,\n",
    "                                              _weight=pe,\n",
    "                                              _freeze=True)\n",
    "        return embedding\n",
    "\n",
    "    def _reverse_position_embedding(self, \n",
    "                                    input_ids:torch.Tensor, \n",
    "                                    target_len:Optional[torch.Tensor]=None)->torch.Tensor:\n",
    "        \"\"\"Computes reversed position indices for the decoder inputs.\"\"\"\n",
    "        mask = ~torch.isin(input_ids,torch.tensor([tokenizer.pad_token_id]))\n",
    "\n",
    "        reversed_position_input  = torch.ones(mask.shape) * mask \n",
    "        \n",
    "        if target_len is None:\n",
    "            reversed_position_input = torch.flip(torch.flip(reversed_position_input , dims=(1,)).cumsum(dim=1), dims=(1,)) \n",
    "        else:\n",
    "            for k in range(input_ids.size(-1)):\n",
    "                reversed_position_input[:,k] = self.relu(target_len -k)\n",
    "\n",
    "        #Add a gaussian noise\n",
    "        normal_round = torch.randn(reversed_position_input.shape) * mask\n",
    "        reversed_position_input = torch.abs(torch.round(reversed_position_input  + normal_round)).to(torch.long) #add a gausian noise and converte to long\n",
    "\n",
    "\n",
    "        return reversed_position_input\n",
    "\n",
    "    def forward(self, \n",
    "                input_ids:torch.Tensor, \n",
    "                attention_mask:Optional[torch.Tensor]=None, \n",
    "                decoder_input_ids:Optional[torch.Tensor]=None, \n",
    "                decoder_attention_mask:Optional[torch.Tensor]=None,\n",
    "                target_len:Optional[torch.Tensor]=None,\n",
    "                labels:Optional[torch.Tensor]=None, \n",
    "                **kwargs):\n",
    "        \"\"\"Overrides forward to inject reversed position embeddings into the decoder.\"\"\"\n",
    "   \n",
    "        # Compute reversed position indices\n",
    "        reversed_position_input = self._reverse_position_embedding(decoder_input_ids, target_len)\n",
    "        \n",
    "        # Get reversed position embeddings\n",
    "        reversed_position_embeddings = self.embed_reverse_positions(reversed_position_input)\n",
    "\n",
    "        #Get position embeddings \n",
    "        position_embeddings = self.model.decoder.embed_positions(decoder_input_ids)\n",
    "\n",
    "        # Compute standard token embeddings\n",
    "        decoder_inputs_embeds = self.model.decoder.embed_tokens(decoder_input_ids) + reversed_position_embeddings + position_embeddings\n",
    "\n",
    "        # Call the original BART forward function with modified decoder inputs\n",
    "        return super().forward(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            decoder_inputs_embeds=decoder_inputs_embeds,\n",
    "            decoder_attention_mask=decoder_attention_mask,\n",
    "            labels=labels,\n",
    "            **kwargs\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RepilotBartForConditionalGeneration were not initialized from the model checkpoint at facebook/bart-large and are newly initialized: ['embed_reverse_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "MODEL_HUB = \"facebook/bart-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_HUB, clean_up_tokenization_spaces=True)\n",
    "model = RepilotBartForConditionalGeneration.from_pretrained(MODEL_HUB)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RepilotBartForConditionalGeneration initialized successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RepilotBartForConditionalGeneration were not initialized from the model checkpoint at facebook/bart-large and are newly initialized: ['embed_reverse_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The following `model_kwargs` are not used by the model: ['input'] (note: typos in the generate arguments will also show up in this list)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[127], line 116\u001b[0m\n\u001b[1;32m    113\u001b[0m target_len \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m8\u001b[39m])\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# Generate Summary\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m summary_ids \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28mprint\u001b[39m(tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(summary_ids, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, clean_up_tokenization_spaces\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "File \u001b[0;32m~/Bureau/length-control-for-summarization/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Bureau/length-control-for-summarization/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:1805\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1803\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# Pull this out first, we only use it for stopping criteria\u001b[39;00m\n\u001b[1;32m   1804\u001b[0m generation_config, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_generation_config(generation_config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1805\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_model_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1806\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_assistant(assistant_model)\n\u001b[1;32m   1808\u001b[0m \u001b[38;5;66;03m# 2. Set generation parameters if not already defined\u001b[39;00m\n",
      "File \u001b[0;32m~/Bureau/length-control-for-summarization/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:1205\u001b[0m, in \u001b[0;36mGenerationMixin._validate_model_kwargs\u001b[0;34m(self, model_kwargs)\u001b[0m\n\u001b[1;32m   1202\u001b[0m         unused_model_args\u001b[38;5;241m.\u001b[39mappend(key)\n\u001b[1;32m   1204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unused_model_args:\n\u001b[0;32m-> 1205\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1206\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following `model_kwargs` are not used by the model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00munused_model_args\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (note: typos in the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1207\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m generate arguments will also show up in this list)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1208\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: The following `model_kwargs` are not used by the model: ['input'] (note: typos in the generate arguments will also show up in this list)"
     ]
    }
   ],
   "source": [
    "\n",
    "_CHECKPOINT_FOR_DOC = \"facebook/bart-large\"\n",
    "_CONFIG_FOR_DOC = \"BartConfig\"\n",
    "\n",
    "\n",
    "class RepilotBartForConditionalGeneration(BartForConditionalGeneration):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        # Define the reversed position embedding module\n",
    "        self.embed_reverse_positions = self._create_reverse_position_embedding()\n",
    "        print(\"RepilotBartForConditionalGeneration initialized successfully.\")\n",
    "        \n",
    "\n",
    "    def _create_reverse_position_embedding(self):\n",
    "        \"\"\"Creates sinusoidal reversed position embeddings.\"\"\"\n",
    "        d_model = self.config.d_model\n",
    "        max_len = self.config.max_position_embeddings\n",
    "        padding_idx = self.config.pad_token_id\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(-2 * (torch.arange(0, d_model) // 2) / d_model * math.log(10000.0))\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term[0::2])\n",
    "        pe[:, 1::2] = torch.cos(position * div_term[1::2])\n",
    "\n",
    "        embedding = nn.Embedding(num_embeddings=max_len,\n",
    "                                              embedding_dim=d_model,\n",
    "                                              padding_idx=padding_idx,\n",
    "                                              _weight=pe,\n",
    "                                              _freeze=True)\n",
    "        return embedding\n",
    "\n",
    "    def _reverse_position_embedding(self, \n",
    "                                    input_ids:torch.Tensor, \n",
    "                                    target_len:Optional[torch.Tensor]=None)->torch.Tensor:\n",
    "        \"\"\"Computes reversed position indices for the decoder inputs.\"\"\"\n",
    "        mask = ~torch.isin(input_ids,torch.tensor([self.config.pad_token_id]))\n",
    "\n",
    "        reversed_position_input  = torch.ones(mask.shape) * mask \n",
    "        \n",
    "        if target_len is None:\n",
    "            reversed_position_input = torch.flip(torch.flip(reversed_position_input , dims=(1,)).cumsum(dim=1), dims=(1,))\n",
    "            print(reversed_position_input)\n",
    "        else:\n",
    "            for k in range(input_ids.size(-1)):\n",
    "                reversed_position_input[:,k] = F.relu(target_len -k)\n",
    "                print(reversed_position_input[:,k])\n",
    "\n",
    "        #Add a gaussian noise\n",
    "        normal_round = torch.randn(reversed_position_input.shape) * mask\n",
    "        reversed_position_input = torch.abs(torch.round(reversed_position_input  + normal_round)).to(torch.long) #add a gausian noise and converte to long\n",
    "\n",
    "\n",
    "        return reversed_position_input\n",
    "\n",
    "    def forward(self, \n",
    "                input_ids:Optional[torch.Tensor]=None, \n",
    "                attention_mask:Optional[torch.Tensor]=None, \n",
    "                decoder_input_ids:Optional[torch.Tensor]=None, \n",
    "                decoder_attention_mask:Optional[torch.Tensor]=None,\n",
    "                target_len:Optional[torch.Tensor]=None,\n",
    "                decoder_inputs_embeds:Optional[torch.Tensor]=None,\n",
    "                labels:Optional[torch.Tensor]=None, \n",
    "                **kwargs):\n",
    "        \"\"\"Overrides forward to inject reversed position embeddings into the decoder.\"\"\"\n",
    "\n",
    "        if input_ids is not None:\n",
    "            print(f\"Forward called with input_ids shape: {input_ids.shape}\")\n",
    "            print(input_ids)\n",
    "        else:\n",
    "            print(\"Forward called with input_ids=None\")\n",
    "            # logger.warning(\"Forward called with input_ids=None\")\n",
    "\n",
    "        if decoder_input_ids is not None:\n",
    "            # Compute reversed position indices\n",
    "            reversed_position_input = self._reverse_position_embedding(decoder_input_ids, target_len)\n",
    "            # logger.debug(f\"decoder_input_ids shape: {decoder_input_ids.shape}\")\n",
    "            print(reversed_position_input)\n",
    "            \n",
    "            # Get reversed position embeddings\n",
    "            reversed_position_embeddings = self.embed_reverse_positions(reversed_position_input)\n",
    "\n",
    "            #Get position embeddings \n",
    "            #position_embeddings = self.model.decoder.embed_positions(decoder_input_ids)\n",
    "\n",
    "            # Compute standard token embeddings\n",
    "            decoder_inputs_embeds = self.model.decoder.embed_tokens(decoder_input_ids) + reversed_position_embeddings #+ position_embeddings\n",
    "            # logger.debug(f\"decoder_inputs_embeds shape: {decoder_inputs_embeds.shape}\")\n",
    "\n",
    "        # Call the original BART forward function with modified decoder inputs\n",
    "        outputs =  super().forward(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            decoder_inputs_embeds=decoder_inputs_embeds,\n",
    "            decoder_attention_mask=decoder_attention_mask,\n",
    "            labels=labels,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        # logger.info(\"Forward pass completed.\")\n",
    "        return outputs\n",
    "    \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(_CHECKPOINT_FOR_DOC, clean_up_tokenization_spaces=True)\n",
    "model = RepilotBartForConditionalGeneration.from_pretrained(_CHECKPOINT_FOR_DOC)\n",
    "\n",
    "##SUMMARY TASK\n",
    "\n",
    "ARTICLE_TO_SUMMARIZE = \"PG&E stated it scheduled the blackouts in response to forecasts for high winds amid dry conditions.The aim is to reduce the risk of wildfires. Nearly 800 thousand customers were scheduled to be affected by the shutoffs which were expected to last through at least midday tomorrow.\"\n",
    "\n",
    "inputs = tokenizer([ARTICLE_TO_SUMMARIZE], max_length=model.config.max_position_embeddings, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "target_len = torch.tensor([8])\n",
    "\n",
    "# Generate Summary\n",
    "summary_ids = model.generate(input=inputs[\"input_ids\"], num_beams = 2, max_length = 4, target_len=torch.tensor([8]))\n",
    "print(tokenizer.batch_decode(summary_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward called with input_ids shape: torch.Size([1, 56])\n",
      "tensor([[    0,  8332,   947,   717,  2305,    24,  1768,     5,   909,  4518,\n",
      "            11,  1263,     7,  5876,    13,   239,  2372,  2876,  3841,  1274,\n",
      "             4,   133,  4374,    16,     7,  1888,     5,   810,     9, 12584,\n",
      "             4,  9221,  5735,  7673,   916,    58,  1768,     7,    28,  2132,\n",
      "            30,     5,  2572, 10816,    61,    58,   421,     7,    94,   149,\n",
      "            23,   513, 15372,  3859,     4,     2]])\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_ids = model.generate(\n",
    "              input_ids = batch[\"input_ids\"],\n",
    "              attention_mask = batch[\"attention_mask\"],\n",
    "              target_len=batch[\"target_len\"],        \n",
    "              )   \n",
    "            \n",
    "# Compute ROUGE scores here\n",
    "generated_txt = [text for text in tokenizer.batch_decode(generated_ids, skip_special_tokens=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TXT = \"My friends are <mask> but they eat too many carbs.\"\n",
    "input_ids = tokenizer([TXT], return_tensors=\"pt\")[\"input_ids\"]\n",
    "\n",
    "masked_index = (input_ids[0] == tokenizer.mask_token_id).nonzero()\n",
    "\n",
    "masked_index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
