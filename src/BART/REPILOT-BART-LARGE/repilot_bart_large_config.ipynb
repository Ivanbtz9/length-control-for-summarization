{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bart large configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODULES ###\n",
    "\n",
    "import sys,os\n",
    "import tqdm\n",
    "import csv\n",
    "from datetime import datetime \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "import torch\n",
    "from torch import cuda\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# Load the ROUGE metric\n",
    "import evaluate\n",
    "\n",
    "from transformers import AutoTokenizer, BartForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import logging\n",
    "from typing import List, Optional, Tuple, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_PROCS =  12\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "NUM_PROCS = os.cpu_count() \n",
    "\n",
    "print(\"NUM_PROCS = \" ,NUM_PROCS)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SEED = 42\n",
    "NUM_LOADER = 4 #config['config_machine'][\"NUM_LOADER\"] #depends of the number of thread \n",
    "\n",
    "\n",
    "# Set random seeds and deterministic pytorch for reproducibility\n",
    "torch.manual_seed(SEED) # pytorch random seed\n",
    "np.random.seed(SEED) # numpy random seed\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset CNN daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['article', 'highlights', 'id'],\n",
      "        num_rows: 14355\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['article', 'highlights', 'id'],\n",
      "        num_rows: 668\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['article', 'highlights', 'id'],\n",
      "        num_rows: 574\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Load CNN/DailyMail dataset\n",
    "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")\n",
    "\n",
    "## Comment this part for the real training time :\n",
    "\n",
    "percentage = 0.05\n",
    "\n",
    "for split in dataset: \n",
    "    dataset[split] = dataset[split].shuffle(seed=SEED).select(range(int(len(dataset[split]) * percentage)))\n",
    "\n",
    "# Check the dataset structure\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load the model and tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n",
      "<class 'transformers.models.bart.tokenization_bart_fast.BartTokenizerFast'>\n",
      "BartTokenizerFast(name_or_path='facebook/bart-large', vocab_size=50265, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t50264: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "### Load model ###\n",
    "MODEL_HUB = 'facebook/bart-large'\n",
    "# Load Model and Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_HUB, clean_up_tokenization_spaces=True)\n",
    "# model = BartForConditionalGeneration.from_pretrained(MODEL_HUB, forced_bos_token_id=0)\n",
    "print(tokenizer.model_max_length)\n",
    "print(type(tokenizer))\n",
    "# print(type(model))\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def len_distrib(batch):\n",
    "\n",
    "#     len_articles = []\n",
    "#     len_highlights = []\n",
    "    \n",
    "#     for article, highlight in zip(batch[\"article\"], batch[\"highlights\"]):\n",
    "#         len_articles.append(len(tokenizer(article, truncation=False)[\"input_ids\"]))\n",
    "#         len_highlights.append(len(tokenizer(highlight, truncation=False)[\"input_ids\"]))\n",
    "\n",
    "\n",
    "#     source = tokenizer(batch[\"article\"],truncation=True, max_length=tokenizer.model_max_length,padding='max_length')\n",
    "#     resume = tokenizer(batch[\"highlights\"],truncation=True, max_length=tokenizer.model_max_length,padding='max_length')\n",
    "\n",
    "#     return {\n",
    "#         'input_ids': source['input_ids'], \n",
    "#         'input_mask': source['attention_mask'],\n",
    "#         'input_len': len_articles,\n",
    "#         'target_ids': resume['input_ids'], \n",
    "#         'target_mask': resume['attention_mask'],\n",
    "#         'target_len': len_highlights\n",
    "#         }\n",
    "\n",
    "def len_distrib(batch):\n",
    "\n",
    "    len_articles = []\n",
    "    len_highlights = []\n",
    "    \n",
    "    for article, highlight in zip(batch[\"article\"], batch[\"highlights\"]):\n",
    "        len_articles.append(len(tokenizer(article, truncation=False)[\"input_ids\"])-1) #Add -1 to skip the <bos> token \n",
    "        len_highlights.append(len(tokenizer(highlight, truncation=False)[\"input_ids\"])-1) #Add -1 to skip the <bos> token \n",
    "\n",
    "\n",
    "    source = tokenizer(batch[\"article\"],truncation=True, max_length=tokenizer.model_max_length)\n",
    "    resume = tokenizer(batch[\"highlights\"],truncation=True, max_length=tokenizer.model_max_length)\n",
    "\n",
    "    return {\n",
    "        'input_ids': source['input_ids'], \n",
    "        'input_mask': source['attention_mask'],\n",
    "        'input_len': len_articles,\n",
    "        'target_ids': resume['input_ids'], \n",
    "        'target_mask': resume['attention_mask'],\n",
    "        'target_len': len_highlights\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(len_distrib,num_proc=NUM_PROCS,batched=True,batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the custom collate function\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function that add padding for each batch.\n",
    "    \"\"\"\n",
    "\n",
    "    # Pad the tokenized content\n",
    "    input_ids = [torch.tensor(item['input_ids'], dtype=torch.long) for item in batch]\n",
    "    input_ids = pad_sequence(input_ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    \n",
    "    attention_mask = [torch.tensor(item['input_mask'], dtype=torch.long) for item in batch]\n",
    "    attention_mask = pad_sequence(attention_mask, batch_first=True, padding_value=0)\n",
    "\n",
    "    decoder_input_ids  = [torch.tensor(item['target_ids'][:-1], dtype=torch.long) for item in batch]\n",
    "    decoder_input_ids = pad_sequence(decoder_input_ids, batch_first=True, padding_value=tokenizer.pad_token_id)     \n",
    "    \n",
    "    decoder_attention_mask = [torch.tensor(item['target_mask'][:-1], dtype=torch.long) for item in batch]\n",
    "    decoder_attention_mask = pad_sequence(decoder_attention_mask, batch_first=True, padding_value=0)\n",
    "    \n",
    "    input_len = torch.tensor([item['input_len'] for item in batch], dtype=torch.long)\n",
    "\n",
    "    target_len = torch.tensor([item['target_len'] for item in batch], dtype=torch.long)\n",
    "\n",
    "    # Labels should be the same as decoder_input_ids (BART-style training)\n",
    "    labels = [torch.tensor(item['target_ids'][1:], dtype=torch.long) for item in batch]\n",
    "    labels = pad_sequence(labels, batch_first=True, padding_value=tokenizer.pad_token_id)  \n",
    "    labels[labels == tokenizer.pad_token_id] = -100  # Ignore padding in loss computation\n",
    "\n",
    "    return {\n",
    "        'input_ids':input_ids,\n",
    "        'attention_mask':attention_mask,\n",
    "        'decoder_input_ids':decoder_input_ids,\n",
    "        'decoder_attention_mask':decoder_attention_mask,\n",
    "        'labels': labels,\n",
    "        'input_len': input_len,\n",
    "        'target_len': target_len\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    0,  2765,   479,  ...,     1,     1,     1],\n",
      "        [    0,   250,  3828,  ...,     5,  1151,     2],\n",
      "        [    0,   250, 17052,  ...,     1,     1,     1],\n",
      "        [    0,   970,    58,  ...,     1,     1,     1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'decoder_input_ids': tensor([[    0,  9058,  2152,  4935,  1746,     7,    49,  1420,     8,    58,\n",
      "          1654,     7, 29327,   877,   479, 50118, 25496,   643,  1710,     6,\n",
      "            65,    19,  1473,  9377,  9308,    11,   255,  1879,  6483,     6,\n",
      "          2627,   479, 50118, 11329, 12807,   333,   303, 23797,  3675,   571,\n",
      "           668,  8344, 13374,     8,   342,    24,    11,   760,    50,    10,\n",
      "           668,   479,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0,   104,  4774,   256,  7706,  1073, 14190,   174,    39,   985,\n",
      "            11,    10,  2673,  1028,   486,    14,    24,    21,   128,   102,\n",
      "          3844,     9,   127,    86,   108,     7,   652,    39,  1802,    18,\n",
      "           284,    23,   296,    18,  9137,  1576,   479, 50118,  4148,     5,\n",
      "           486,     6,    39,   985,  2966,   123,     7,   652,   106,     6,\n",
      "           584,    51,    58,    11, 32248,   479, 50118,  9962,  3969,  1882,\n",
      "             5,  2311,     7, 14514,     5,  1576,    15,   294,   479, 50118,\n",
      "           448,  7706,  1073, 14190,    21,  3828,     9, 20669,     8,  2429,\n",
      "          4690, 18985,     6,   753,     6,    11,    39,   188, 10372,  3537,\n",
      "            11,  1125,    71,    79,  5898, 16368,    39,  9766,   479],\n",
      "        [    0,   250,  1150,     6,   985,     8,    49,   664,  1354,    58,\n",
      "           848,    11,     5,  2058,   479, 50118,   133,   985,     8,  1928,\n",
      "           962,    23,     5,  1310,   583,  1777, 16744,   118,     6,  4769,\n",
      "           479, 50118, 40589,     6,  3191,     6,    21,  2047,     7,    28,\n",
      "             5,  1393,     8,    21,  8240,    13,    80,   722,   479, 50118,\n",
      "           133,  2143,     8,   277,   664,  2761,  5601,     5,  2058,   479,\n",
      "         50118,   133,  2143,     6,   290,     6,  2152,  1746,   150,     5,\n",
      "          1816,     6,   155,     6,  5601,  2260, 21219, 27205,   479, 50118,\n",
      "         28860,    16,  7092, 31164,    10, 14327,   326, 25561,  4649,    25,\n",
      "            37,  8842,    23,     5,  1098,   479,     1,     1,     1],\n",
      "        [    0, 14563,  7414,  3741, 30753,    88, 19664,   257,  1851,   148,\n",
      "           777,   623,   968,   507,   479, 50118,   133,   177,    21,  3016,\n",
      "           321,    12,   288,   227,  1600,     8,  5244,    11,  2910,   479,\n",
      "         50118,   243,  1146,   124,  6180,     9,  1811,   783,  8365,    18,\n",
      "          1539,    15, 20110, 15819,    11, 12910,   479, 50118, 28586,   869,\n",
      "            21,   823,   848,    11, 26757,  1160,   479,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1]]), 'decoder_attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'labels': tensor([[ 9058,  2152,  4935,  1746,     7,    49,  1420,     8,    58,  1654,\n",
      "             7, 29327,   877,   479, 50118, 25496,   643,  1710,     6,    65,\n",
      "            19,  1473,  9377,  9308,    11,   255,  1879,  6483,     6,  2627,\n",
      "           479, 50118, 11329, 12807,   333,   303, 23797,  3675,   571,   668,\n",
      "          8344, 13374,     8,   342,    24,    11,   760,    50,    10,   668,\n",
      "           479,     2,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],\n",
      "        [  104,  4774,   256,  7706,  1073, 14190,   174,    39,   985,    11,\n",
      "            10,  2673,  1028,   486,    14,    24,    21,   128,   102,  3844,\n",
      "             9,   127,    86,   108,     7,   652,    39,  1802,    18,   284,\n",
      "            23,   296,    18,  9137,  1576,   479, 50118,  4148,     5,   486,\n",
      "             6,    39,   985,  2966,   123,     7,   652,   106,     6,   584,\n",
      "            51,    58,    11, 32248,   479, 50118,  9962,  3969,  1882,     5,\n",
      "          2311,     7, 14514,     5,  1576,    15,   294,   479, 50118,   448,\n",
      "          7706,  1073, 14190,    21,  3828,     9, 20669,     8,  2429,  4690,\n",
      "         18985,     6,   753,     6,    11,    39,   188, 10372,  3537,    11,\n",
      "          1125,    71,    79,  5898, 16368,    39,  9766,   479,     2],\n",
      "        [  250,  1150,     6,   985,     8,    49,   664,  1354,    58,   848,\n",
      "            11,     5,  2058,   479, 50118,   133,   985,     8,  1928,   962,\n",
      "            23,     5,  1310,   583,  1777, 16744,   118,     6,  4769,   479,\n",
      "         50118, 40589,     6,  3191,     6,    21,  2047,     7,    28,     5,\n",
      "          1393,     8,    21,  8240,    13,    80,   722,   479, 50118,   133,\n",
      "          2143,     8,   277,   664,  2761,  5601,     5,  2058,   479, 50118,\n",
      "           133,  2143,     6,   290,     6,  2152,  1746,   150,     5,  1816,\n",
      "             6,   155,     6,  5601,  2260, 21219, 27205,   479, 50118, 28860,\n",
      "            16,  7092, 31164,    10, 14327,   326, 25561,  4649,    25,    37,\n",
      "          8842,    23,     5,  1098,   479,     2,  -100,  -100,  -100],\n",
      "        [14563,  7414,  3741, 30753,    88, 19664,   257,  1851,   148,   777,\n",
      "           623,   968,   507,   479, 50118,   133,   177,    21,  3016,   321,\n",
      "            12,   288,   227,  1600,     8,  5244,    11,  2910,   479, 50118,\n",
      "           243,  1146,   124,  6180,     9,  1811,   783,  8365,    18,  1539,\n",
      "            15, 20110, 15819,    11, 12910,   479, 50118, 28586,   869,    21,\n",
      "           823,   848,    11, 26757,  1160,   479,     2,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100]]), 'input_len': tensor([ 330, 1392,  726,  497]), 'target_len': tensor([52, 99, 96, 57])}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_params = {\n",
    "    'batch_size': 4,\n",
    "    'shuffle': True,\n",
    "    'collate_fn':collate_fn,\n",
    "    'num_workers': NUM_LOADER,\n",
    "    'pin_memory': True  #  Enables faster GPU transfers\n",
    "    }\n",
    "\n",
    "eval_params = {\n",
    "    'batch_size': 4,\n",
    "    'shuffle': False,\n",
    "    'collate_fn':collate_fn,\n",
    "    'num_workers': NUM_LOADER,\n",
    "    'pin_memory': True  #  Enables faster GPU transfers\n",
    "    }\n",
    "\n",
    "\n",
    "# This will be used down for training and validation stage for the model.\n",
    "train_loader = DataLoader(dataset[\"train\"], **train_params)\n",
    "eval_loader = DataLoader(dataset[\"validation\"], **eval_params)\n",
    "\n",
    "for batch in train_loader:\n",
    "    print(batch)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create reverse embedding for the Bart model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<class 'transformers.models.bart.modeling_bart.BartForConditionalGeneration'>, <class 'transformers.models.bart.modeling_bart.BartPreTrainedModel'>, <class 'transformers.modeling_utils.PreTrainedModel'>, <class 'torch.nn.modules.module.Module'>, <class 'transformers.modeling_utils.ModuleUtilsMixin'>, <class 'transformers.generation.utils.GenerationMixin'>, <class 'transformers.utils.hub.PushToHubMixin'>, <class 'transformers.integrations.peft.PeftAdapterMixin'>, <class 'object'>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Get all parent classes in the MRO (Method Resolution Order)\n",
    "print(BartForConditionalGeneration.__mro__)\n",
    "tokenizer.bos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "torch.Size([4, 99])\n",
      "torch.Size([4, 99])\n",
      "torch.Size([4, 99])\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.pad_token_id)\n",
    "\n",
    "mask = ~torch.isin(batch[\"decoder_input_ids\"],torch.tensor([tokenizer.pad_token_id,tokenizer.eos_token_id])) # mask with 0 where a pad_id is present\n",
    "print(mask.shape)\n",
    "\n",
    "reversed_position_input  = torch.ones(mask.shape) * mask # [1,1,1,0,0] \n",
    "\n",
    "reversed_position_input = torch.flip(torch.flip(reversed_position_input , dims=(1,)).cumsum(dim=1), dims=(1,))  \n",
    "\n",
    "print(reversed_position_input.shape)\n",
    "\n",
    "normal_round = torch.randn(batch[\"decoder_input_ids\"].shape) * mask\n",
    "\n",
    "reversed_position_input = torch.abs(torch.round(reversed_position_input  + normal_round)).to(torch.long) #add a gausian noise and converte to long\n",
    "\n",
    "print(reversed_position_input.shape)\n",
    "\n",
    "# input_decoder_position_embedding = model.model.decoder.embed_positions(reversed_position_input)\n",
    "\n",
    "# input_decoder_position_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code pour les index de positions inversées "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 111])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "relu = nn.ReLU()\n",
    "\n",
    "def _reverse_position_embedding(input_ids:torch.Tensor,\n",
    "                                target_len:Optional[torch.Tensor]=None)->torch.Tensor:\n",
    "    \n",
    "    mask = ~torch.isin(input_ids,torch.tensor([tokenizer.pad_token_id])) # mask with 0 where a pad_id is present\n",
    "\n",
    "    reversed_position_input  = torch.ones(mask.shape) * mask # Put 1 where there are token index and 0 where there are pad index[1,1,1,0,0] \n",
    "    \n",
    "    if target_len is None:\n",
    "        reversed_position_input = torch.flip(torch.flip(reversed_position_input , dims=(1,)).cumsum(dim=1), dims=(1,)) \n",
    "        #[[ 54,  53, ...,0,  0],[100, 101,...,1]]\n",
    "        #print(reversed_position_input.shape)\n",
    "    else:\n",
    "        for k in range(input_ids.size(-1)):\n",
    "            reversed_position_input[:,k] = relu(target_len -k)\n",
    "\n",
    "    #Add a gaussian noise\n",
    "    normal_round = torch.randn(reversed_position_input.shape) * mask\n",
    "\n",
    "    reversed_position_input = torch.abs(torch.round(reversed_position_input  + normal_round)).to(torch.long) #add a gausian noise and converte to long\n",
    "\n",
    "\n",
    "    return reversed_position_input\n",
    "\n",
    "reversed_position_input = _reverse_position_embedding(batch[\"decoder_input_ids\"])\n",
    "print(reversed_position_input.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code pour les embeddings de position sinus/cosinus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([4, 111, 1024])\n"
     ]
    }
   ],
   "source": [
    "# # dir(model.model.decoder.layernorm_embedding)\n",
    "\n",
    "d_model = model.config.d_model\n",
    "max_len = tokenizer.model_max_length\n",
    "\n",
    "pe = torch.zeros(max_len, d_model)\n",
    "position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "div_term = torch.exp((-2*torch.arange(0, d_model)//2)/d_model * math.log(10000.0) )\n",
    "\n",
    "print(div_term.shape)\n",
    "\n",
    "print((position*div_term).shape)\n",
    "\n",
    "\n",
    "pe[:, 0::2] = torch.sin(position*div_term[0::2] )\n",
    "pe[:, 1::2] = torch.cos(position*div_term[1::2])\n",
    "\n",
    "embed_reverse_positions = nn.Embedding(num_embeddings=tokenizer.model_max_length,\n",
    "                                              embedding_dim=d_model,\n",
    "                                              padding_idx=tokenizer.pad_token_id,\n",
    "                                              _weight=pe,\n",
    "                                              _freeze=True)\n",
    "\n",
    "print(embed_reverse_positions(reversed_position_input).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BartDecoder(\n",
      "  (embed_tokens): BartScaledWordEmbedding(50265, 1024, padding_idx=1)\n",
      "  (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
      "  (layers): ModuleList(\n",
      "    (0-11): 12 x BartDecoderLayer(\n",
      "      (self_attn): BartSdpaAttention(\n",
      "        (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      )\n",
      "      (activation_fn): GELUActivation()\n",
      "      (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (encoder_attn): BartSdpaAttention(\n",
      "        (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      )\n",
      "      (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "      (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "      (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "torch.Size([4, 111, 1024])\n",
      "torch.Size([4, 111, 1024])\n",
      "torch.Size([4, 111, 1024])\n"
     ]
    }
   ],
   "source": [
    "print(model.model.decoder)\n",
    "token_embeddings = model.model.decoder.embed_tokens(batch[\"decoder_input_ids\"]) \n",
    "print(token_embeddings.shape)\n",
    "position_embeddings = model.model.decoder.embed_positions(batch[\"decoder_input_ids\"]) \n",
    "print(position_embeddings.shape)\n",
    "repilot_embeddings = embed_reverse_positions(_reverse_position_embedding(batch[\"decoder_input_ids\"]))\n",
    "print(repilot_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs_embeds = token_embeddings + position_embeddings + repilot_embeddings\n",
    "output = model(input_ids=batch[\"input_ids\"], \n",
    "               attention_mask=batch[\"attention_mask\"],\n",
    "               decoder_attention_mask=batch[\"decoder_attention_mask\"], \n",
    "               decoder_inputs_embeds=decoder_inputs_embeds,\n",
    "               labels=batch[\"labels\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code pour la classe RepilotBartForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger __main__ (DEBUG)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"PyTorch REPILOT_BART model.\"\"\"\n",
    "import copy\n",
    "import math\n",
    "import logging\n",
    "from typing import List, Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.checkpoint\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "\n",
    "from transformers import BartForConditionalGeneration, AutoTokenizer\n",
    "from transformers.modeling_outputs import (\n",
    "    BaseModelOutput,\n",
    "    BaseModelOutputWithPastAndCrossAttentions,\n",
    "    CausalLMOutputWithCrossAttentions,\n",
    "    Seq2SeqLMOutput,\n",
    "    Seq2SeqModelOutput,\n",
    "    Seq2SeqQuestionAnsweringModelOutput,\n",
    "    Seq2SeqSequenceClassifierOutput,\n",
    ")\n",
    "from transformers.modeling_utils import PreTrainedModel\n",
    "from transformers.utils import (\n",
    "    add_code_sample_docstrings,\n",
    "    add_end_docstrings,\n",
    "    add_start_docstrings,\n",
    "    add_start_docstrings_to_model_forward,\n",
    "    is_flash_attn_2_available,\n",
    "    is_flash_attn_greater_or_equal_2_10,\n",
    "    replace_return_docstrings,\n",
    ")\n",
    "from transformers import BartConfig, AutoTokenizer\n",
    "\n",
    "if is_flash_attn_2_available():\n",
    "    from transformers.modeling_flash_attention_utils import _flash_attention_forward\n",
    "\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.DEBUG, \n",
    "                    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
    "                    handlers=[\n",
    "                        logging.StreamHandler()  #log to console\n",
    "                    ])\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "_CHECKPOINT_FOR_DOC = \"facebook/bart-large\"\n",
    "_CONFIG_FOR_DOC = \"BartConfig\"\n",
    "\n",
    "logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 11:23:02,406 - urllib3.connectionpool - DEBUG - Resetting dropped connection: huggingface.co\n",
      "2025-03-21 11:23:02,614 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /facebook/bart-large/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "2025-03-21 11:23:02,855 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /facebook/bart-large/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-03-21 11:23:02,973 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /facebook/bart-large/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-03-21 11:23:03,092 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /facebook/bart-large/resolve/main/model.safetensors HTTP/1.1\" 404 0\n",
      "2025-03-21 11:23:03,586 - __main__ - INFO - Iitialized sinusoidal position embedding successfully.\n",
      "2025-03-21 11:23:03,586 - __main__ - INFO - RepilotBartForConditionalGeneration initialized successfully.\n",
      "Some weights of RepilotBartForConditionalGeneration were not initialized from the model checkpoint at facebook/bart-large and are newly initialized: ['embed_reverse_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-03-21 11:23:04,512 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /facebook/bart-large/resolve/main/generation_config.json HTTP/1.1\" 404 0\n"
     ]
    }
   ],
   "source": [
    "class RepilotBartForConditionalGeneration(BartForConditionalGeneration):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        # Define the reversed position embedding module\n",
    "        self.embed_reverse_positions = self._create_sinusoidal_position_embedding()\n",
    "        logger.info(\"RepilotBartForConditionalGeneration initialized successfully.\")\n",
    "        \n",
    "\n",
    "    def _create_sinusoidal_position_embedding(self)->torch.nn.Embedding:\n",
    "        \"\"\"Creates sinusoidal reversed position embeddings.\"\"\"\n",
    "        d_model = self.config.d_model\n",
    "        max_len = self.config.max_position_embeddings\n",
    "        padding_idx = self.config.pad_token_id\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(-2 * ((torch.arange(0, d_model) // 2) / d_model) * math.log(10000.0))\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term[0::2])\n",
    "        pe[:, 1::2] = torch.cos(position * div_term[1::2])\n",
    "\n",
    "        embedding = nn.Embedding(num_embeddings=max_len,\n",
    "                                embedding_dim=d_model,\n",
    "                                padding_idx=padding_idx,\n",
    "                                _weight=pe,\n",
    "                                _freeze=True)\n",
    "        \n",
    "        logger.info(\"Iitialized sinusoidal position embedding successfully.\")\n",
    "        return embedding\n",
    "\n",
    "    def _get_reverse_position_decoder_ids(self, decoder_input_ids:torch.LongTensor, target_len:Optional[torch.Tensor]=None, gaussian_noise=True)->torch.LongTensor:\n",
    "        \"\"\"Computes reversed position indices for the decoder inputs.\"\"\"\n",
    "        \n",
    "        mask = ~torch.isin(decoder_input_ids,torch.tensor([self.config.pad_token_id]))\n",
    "\n",
    "        reversed_position_input  = torch.ones(mask.shape) * mask \n",
    "        \n",
    "        if target_len is None:\n",
    "            reversed_position_input = torch.flip(torch.flip(reversed_position_input , dims=(1,)).cumsum(dim=1), dims=(1,))\n",
    "            logger.debug(f\"Shape of reversed_position_input {reversed_position_input.shape}\")\n",
    "\n",
    "        else:\n",
    "            k = torch.arange(decoder_input_ids.size(-1), device=target_len.device)  # Create a tensor [0, 1, 2, ..., seq_len-1]\n",
    "            reversed_position_input = F.relu(target_len.unsqueeze(1) - k)  # Broadcast subtraction over all positions\n",
    "            logger.debug(f\"reversed_position_input shape {reversed_position_input.shape}\")\n",
    "            print(reversed_position_input)\n",
    "\n",
    "        if gaussian_noise:\n",
    "            normal_round = torch.randn(reversed_position_input.shape) * mask\n",
    "        else:\n",
    "            normal_round = 0\n",
    "\n",
    "        reversed_position_input = torch.abs(torch.round(reversed_position_input  + normal_round)).to(torch.long)\n",
    "        logger.debug(f\"reversed_position_input : {reversed_position_input}\")\n",
    "        return reversed_position_input\n",
    "    \n",
    "    def _get_position_decoder_ids(self, decoder_input_ids:torch.LongTensor)->torch.LongTensor:\n",
    "        \"\"\"Computes position indices for the decoder inputs.\"\"\"\n",
    "        \n",
    "        mask = ~torch.isin(decoder_input_ids,torch.tensor([self.config.pad_token_id]))\n",
    "\n",
    "        position_decoder_input_ids  = torch.ones(mask.shape).cumsum(dim=1) * mask \n",
    "        \n",
    "        return position_decoder_input_ids.to(torch.long)\n",
    "    \n",
    "\n",
    "    \n",
    "    def forward(\n",
    "            self, \n",
    "            input_ids: Optional[torch.LongTensor] = None,\n",
    "            attention_mask: Optional[torch.Tensor] = None,\n",
    "            decoder_input_ids: Optional[torch.LongTensor] = None,\n",
    "            decoder_attention_mask: Optional[torch.LongTensor] = None,\n",
    "            head_mask: Optional[torch.Tensor] = None,\n",
    "            decoder_head_mask: Optional[torch.Tensor] = None,\n",
    "            cross_attn_head_mask: Optional[torch.Tensor] = None,\n",
    "            encoder_outputs: Optional[List[torch.FloatTensor]] = None,\n",
    "            past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
    "            inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "            decoder_inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "            labels: Optional[torch.LongTensor] = None,\n",
    "            use_cache: Optional[bool] = None,\n",
    "            output_attentions: Optional[bool] = None,\n",
    "            output_hidden_states: Optional[bool] = None,\n",
    "            return_dict: Optional[bool] = None,\n",
    "            target_len:Optional[torch.Tensor]=None,\n",
    "        )-> Union[Tuple, Seq2SeqLMOutput]:\n",
    "        \"\"\"Overrides forward to inject reversed position embeddings into the decoder.\"\"\"\n",
    "\n",
    "\n",
    "        if input_ids is not None:\n",
    "            logger.info(f\"Forward called with input_ids shape: {input_ids.shape}\")\n",
    "            print(input_ids)\n",
    "        else:\n",
    "            logger.warning(\"Forward called with input_ids=None\")\n",
    "\n",
    "        if decoder_input_ids is not None:\n",
    "\n",
    "            # Get reversed position indices\n",
    "            reversed_position_input_ids = self._get_reverse_position_decoder_ids(decoder_input_ids, target_len)\n",
    "            logger.info(f\"reversed_position_decoder_input_ids shape: {reversed_position_input_ids.shape}\")\n",
    "            print(reversed_position_input_ids)\n",
    "            # Compute reversed position embeddings\n",
    "            reversed_position_embeddings = self.embed_reverse_positions(reversed_position_input_ids)\n",
    "            logger.info(f\"reversed_position_embeddings shape: {reversed_position_embeddings.shape}\")\n",
    "\n",
    "\n",
    "            # Get position indices\n",
    "            position_input_ids = self._get_position_decoder_ids(decoder_input_ids)\n",
    "            logger.info(f\"position_decoder_input_ids shape: {position_input_ids.shape}\")\n",
    "            print(position_input_ids)\n",
    "            \n",
    "            # Compute position embeddings\n",
    "            position_embeddings = self.model.decoder.embed_positions(position_input_ids)\n",
    "            logger.info(f\"position_embeddings shape: {position_embeddings.shape}\")\n",
    "\n",
    "            # Compute standard token embeddings\n",
    "            decoder_inputs_embeds = self.model.decoder.embed_tokens(decoder_input_ids)  + position_embeddings + reversed_position_embeddings\n",
    "            logger.debug(f\"decoder_inputs_embeds shape: {decoder_inputs_embeds.shape}\")\n",
    "\n",
    "            decoder_input_ids = None\n",
    "        else:\n",
    "            logger.warning(\"Forward called with decoder_input_ids=None\")\n",
    "\n",
    "\n",
    "\n",
    "        # Call the original BART forward function with modified decoder inputs\n",
    "        outputs = super().forward(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            decoder_input_ids=decoder_input_ids,\n",
    "            encoder_outputs=encoder_outputs,\n",
    "            decoder_attention_mask=decoder_attention_mask,\n",
    "            head_mask=head_mask,\n",
    "            decoder_head_mask=decoder_head_mask,\n",
    "            cross_attn_head_mask=cross_attn_head_mask,\n",
    "            past_key_values=past_key_values,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            decoder_inputs_embeds=decoder_inputs_embeds,\n",
    "            use_cache=use_cache,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "            labels=labels,\n",
    "        )\n",
    "\n",
    "        logger.info(\"Forward pass completed.\")\n",
    "\n",
    "        return outputs\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(_CHECKPOINT_FOR_DOC, clean_up_tokenization_spaces=True)\n",
    "model = RepilotBartForConditionalGeneration.from_pretrained(_CHECKPOINT_FOR_DOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartConfig {\n",
       "  \"_name_or_path\": \"facebook/bart-large\",\n",
       "  \"activation_dropout\": 0.1,\n",
       "  \"activation_function\": \"gelu\",\n",
       "  \"add_bias_logits\": false,\n",
       "  \"add_final_layer_norm\": false,\n",
       "  \"architectures\": [\n",
       "    \"BartModel\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"classif_dropout\": 0.1,\n",
       "  \"classifier_dropout\": 0.0,\n",
       "  \"d_model\": 1024,\n",
       "  \"decoder_attention_heads\": 16,\n",
       "  \"decoder_ffn_dim\": 4096,\n",
       "  \"decoder_layerdrop\": 0.0,\n",
       "  \"decoder_layers\": 12,\n",
       "  \"decoder_start_token_id\": 2,\n",
       "  \"dropout\": 0.1,\n",
       "  \"early_stopping\": true,\n",
       "  \"encoder_attention_heads\": 16,\n",
       "  \"encoder_ffn_dim\": 4096,\n",
       "  \"encoder_layerdrop\": 0.0,\n",
       "  \"encoder_layers\": 12,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"forced_bos_token_id\": 0,\n",
       "  \"forced_eos_token_id\": 2,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"LABEL_0\",\n",
       "    \"1\": \"LABEL_1\",\n",
       "    \"2\": \"LABEL_2\"\n",
       "  },\n",
       "  \"init_std\": 0.02,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"label2id\": {\n",
       "    \"LABEL_0\": 0,\n",
       "    \"LABEL_1\": 1,\n",
       "    \"LABEL_2\": 2\n",
       "  },\n",
       "  \"max_position_embeddings\": 1024,\n",
       "  \"model_type\": \"bart\",\n",
       "  \"no_repeat_ngram_size\": 3,\n",
       "  \"normalize_before\": false,\n",
       "  \"num_beams\": 4,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"scale_embedding\": false,\n",
       "  \"task_specific_params\": {\n",
       "    \"summarization\": {\n",
       "      \"length_penalty\": 1.0,\n",
       "      \"max_length\": 128,\n",
       "      \"min_length\": 12,\n",
       "      \"num_beams\": 4\n",
       "    },\n",
       "    \"summarization_cnn\": {\n",
       "      \"length_penalty\": 2.0,\n",
       "      \"max_length\": 142,\n",
       "      \"min_length\": 56,\n",
       "      \"num_beams\": 4\n",
       "    },\n",
       "    \"summarization_xsum\": {\n",
       "      \"length_penalty\": 1.0,\n",
       "      \"max_length\": 62,\n",
       "      \"min_length\": 11,\n",
       "      \"num_beams\": 6\n",
       "    }\n",
       "  },\n",
       "  \"transformers_version\": \"4.45.1\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50265\n",
       "}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2387,   964,    32, 50264,    53,    51,  3529,   350,   171, 33237,\n",
       "             4,     2]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "input_ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification partie forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 15:17:42,095 - __main__ - INFO - Forward called with input_ids shape: torch.Size([2, 20])\n",
      "2025-03-19 15:17:42,097 - __main__ - DEBUG - reversed_position_input shape torch.Size([2, 11])\n",
      "2025-03-19 15:17:42,098 - __main__ - DEBUG - reversed_position_input : tensor([[ 7,  7,  6,  3,  3,  3,  2,  0,  0,  0,  0],\n",
      "        [10, 10,  9,  7,  6,  6,  3,  4,  2,  2,  1]])\n",
      "2025-03-19 15:17:42,099 - __main__ - INFO - reversed_position_decoder_input_ids shape: torch.Size([2, 11])\n",
      "2025-03-19 15:17:42,100 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([2, 11, 1024])\n",
      "2025-03-19 15:17:42,100 - __main__ - INFO - position_decoder_input_ids shape: torch.Size([2, 11])\n",
      "2025-03-19 15:17:42,101 - __main__ - INFO - position_embeddings shape: torch.Size([2, 11, 1024])\n",
      "2025-03-19 15:17:42,102 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([2, 11, 1024])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0, 45089,    12, 24641,   154, 30634,    15,     5,  3480,    73,\n",
      "         26339, 23969, 41616,  6890,   484,  2402,     2,     1,     1,     1],\n",
      "        [    0,   100,   236,     7, 33942,     5,  8746,   594, 37215,     9,\n",
      "             5,  1421,  8811,    15,     5, 41616,  1230,  6380,     4,     2]])\n",
      "tensor([[ 7,  6,  5,  4,  3,  2,  1,  0,  0,  0,  0],\n",
      "        [11, 10,  9,  8,  7,  6,  5,  4,  3,  2,  1]])\n",
      "tensor([[ 7,  7,  6,  3,  3,  3,  2,  0,  0,  0,  0],\n",
      "        [10, 10,  9,  7,  6,  6,  3,  4,  2,  2,  1]])\n",
      "tensor([[ 1,  2,  3,  4,  5,  6,  7,  0,  0,  0,  0],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 15:17:42,485 - __main__ - INFO - Forward pass completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 11, 50265])\n"
     ]
    }
   ],
   "source": [
    "output = model(**batch)\n",
    "print(output.logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 15:18:14,872 - __main__ - INFO - Forward called with input_ids shape: torch.Size([1, 13])\n",
      "2025-03-19 15:18:14,873 - __main__ - WARNING - Forward called with decoder_input_ids=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,  2387,   964,    32, 50264,    53,    51,  3529,   350,   171,\n",
      "         33237,     4,     2]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 15:18:15,134 - __main__ - INFO - Forward pass completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 13, 50265])\n",
      "4\n",
      "torch.Size([50265])\n",
      "tensor([0.1021, 0.0865, 0.0459, 0.0372, 0.0362], grad_fn=<TopkBackward0>) tensor([205, 372,  70, 269, 182])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['good', 'great', 'all', 'really', 'very']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TXT = \"My friends are <mask> but they eat too many carbs.\"\n",
    "input_ids = tokenizer.batch_encode_plus([TXT], return_tensors='pt')['input_ids']\n",
    "output =  model(input_ids=input_ids)#, \n",
    "logits = output[0]\n",
    "print(logits.shape)\n",
    "masked_index = (input_ids[0] == tokenizer.mask_token_id).nonzero().item()\n",
    "print(masked_index)\n",
    "probs = logits[0, masked_index].softmax(dim=0)\n",
    "print(probs.shape)\n",
    "values, predictions = probs.topk(5)\n",
    "print(values,predictions)\n",
    "tokenizer.decode(predictions).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50265])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[0, masked_index].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification de la partie generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartConfig {\n",
       "  \"_name_or_path\": \"facebook/bart-large\",\n",
       "  \"activation_dropout\": 0.1,\n",
       "  \"activation_function\": \"gelu\",\n",
       "  \"add_bias_logits\": false,\n",
       "  \"add_final_layer_norm\": false,\n",
       "  \"architectures\": [\n",
       "    \"BartModel\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"classif_dropout\": 0.1,\n",
       "  \"classifier_dropout\": 0.0,\n",
       "  \"d_model\": 1024,\n",
       "  \"decoder_attention_heads\": 16,\n",
       "  \"decoder_ffn_dim\": 4096,\n",
       "  \"decoder_layerdrop\": 0.0,\n",
       "  \"decoder_layers\": 12,\n",
       "  \"decoder_start_token_id\": 2,\n",
       "  \"dropout\": 0.1,\n",
       "  \"early_stopping\": true,\n",
       "  \"encoder_attention_heads\": 16,\n",
       "  \"encoder_ffn_dim\": 4096,\n",
       "  \"encoder_layerdrop\": 0.0,\n",
       "  \"encoder_layers\": 12,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"forced_bos_token_id\": 0,\n",
       "  \"forced_eos_token_id\": 2,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"LABEL_0\",\n",
       "    \"1\": \"LABEL_1\",\n",
       "    \"2\": \"LABEL_2\"\n",
       "  },\n",
       "  \"init_std\": 0.02,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"label2id\": {\n",
       "    \"LABEL_0\": 0,\n",
       "    \"LABEL_1\": 1,\n",
       "    \"LABEL_2\": 2\n",
       "  },\n",
       "  \"max_position_embeddings\": 1024,\n",
       "  \"model_type\": \"bart\",\n",
       "  \"no_repeat_ngram_size\": 3,\n",
       "  \"normalize_before\": false,\n",
       "  \"num_beams\": 4,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"scale_embedding\": false,\n",
       "  \"task_specific_params\": {\n",
       "    \"summarization\": {\n",
       "      \"length_penalty\": 1.0,\n",
       "      \"max_length\": 128,\n",
       "      \"min_length\": 12,\n",
       "      \"num_beams\": 4\n",
       "    },\n",
       "    \"summarization_cnn\": {\n",
       "      \"length_penalty\": 2.0,\n",
       "      \"max_length\": 142,\n",
       "      \"min_length\": 56,\n",
       "      \"num_beams\": 4\n",
       "    },\n",
       "    \"summarization_xsum\": {\n",
       "      \"length_penalty\": 1.0,\n",
       "      \"max_length\": 62,\n",
       "      \"min_length\": 11,\n",
       "      \"num_beams\": 6\n",
       "    }\n",
       "  },\n",
       "  \"transformers_version\": \"4.45.1\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50265\n",
       "}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 17:10:16,654 - __main__ - WARNING - Forward called with input_ids=None\n",
      "2025-03-18 17:10:16,655 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([8, 1])\n",
      "2025-03-18 17:10:16,656 - __main__ - INFO - reversed_position_decoder_input_ids shape: torch.Size([8, 1])\n",
      "2025-03-18 17:10:16,657 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([8, 1, 1024])\n",
      "2025-03-18 17:10:16,658 - __main__ - INFO - position_decoder_input_ids shape: torch.Size([8, 1])\n",
      "2025-03-18 17:10:16,658 - __main__ - INFO - position_embeddings shape: torch.Size([8, 1, 1024])\n",
      "2025-03-18 17:10:16,659 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([8, 1, 1024])\n",
      "2025-03-18 17:10:16,742 - __main__ - INFO - Forward pass completed.\n",
      "2025-03-18 17:10:16,747 - __main__ - WARNING - Forward called with input_ids=None\n",
      "2025-03-18 17:10:16,748 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([8, 1])\n",
      "2025-03-18 17:10:16,749 - __main__ - INFO - reversed_position_decoder_input_ids shape: torch.Size([8, 1])\n",
      "2025-03-18 17:10:16,750 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([8, 1, 1024])\n",
      "2025-03-18 17:10:16,750 - __main__ - INFO - position_decoder_input_ids shape: torch.Size([8, 1])\n",
      "2025-03-18 17:10:16,751 - __main__ - INFO - position_embeddings shape: torch.Size([8, 1, 1024])\n",
      "2025-03-18 17:10:16,752 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([8, 1, 1024])\n",
      "2025-03-18 17:10:16,806 - __main__ - INFO - Forward pass completed.\n",
      "2025-03-18 17:10:16,811 - __main__ - WARNING - Forward called with input_ids=None\n",
      "2025-03-18 17:10:16,812 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([8, 1])\n",
      "2025-03-18 17:10:16,813 - __main__ - INFO - reversed_position_decoder_input_ids shape: torch.Size([8, 1])\n",
      "2025-03-18 17:10:16,814 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([8, 1, 1024])\n",
      "2025-03-18 17:10:16,814 - __main__ - INFO - position_decoder_input_ids shape: torch.Size([8, 1])\n",
      "2025-03-18 17:10:16,815 - __main__ - INFO - position_embeddings shape: torch.Size([8, 1, 1024])\n",
      "2025-03-18 17:10:16,816 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([8, 1, 1024])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1]])\n",
      "tensor([[1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]])\n",
      "tensor([[0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0]])\n",
      "tensor([[1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]])\n",
      "tensor([[2],\n",
      "        [0],\n",
      "        [3],\n",
      "        [1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [0],\n",
      "        [0]])\n",
      "tensor([[1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 17:10:16,883 - __main__ - INFO - Forward pass completed.\n",
      "2025-03-18 17:10:16,889 - __main__ - WARNING - Forward called with input_ids=None\n",
      "2025-03-18 17:10:16,890 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([8, 1])\n",
      "2025-03-18 17:10:16,891 - __main__ - INFO - reversed_position_decoder_input_ids shape: torch.Size([8, 1])\n",
      "2025-03-18 17:10:16,892 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([8, 1, 1024])\n",
      "2025-03-18 17:10:16,893 - __main__ - INFO - position_decoder_input_ids shape: torch.Size([8, 1])\n",
      "2025-03-18 17:10:16,896 - __main__ - INFO - position_embeddings shape: torch.Size([8, 1, 1024])\n",
      "2025-03-18 17:10:16,897 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([8, 1, 1024])\n",
      "2025-03-18 17:10:16,963 - __main__ - INFO - Forward pass completed.\n",
      "2025-03-18 17:10:16,967 - __main__ - WARNING - Forward called with input_ids=None\n",
      "2025-03-18 17:10:16,968 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([8, 1])\n",
      "2025-03-18 17:10:16,968 - __main__ - INFO - reversed_position_decoder_input_ids shape: torch.Size([8, 1])\n",
      "2025-03-18 17:10:16,969 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([8, 1, 1024])\n",
      "2025-03-18 17:10:16,970 - __main__ - INFO - position_decoder_input_ids shape: torch.Size([8, 1])\n",
      "2025-03-18 17:10:16,971 - __main__ - INFO - position_embeddings shape: torch.Size([8, 1, 1024])\n",
      "2025-03-18 17:10:16,971 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([8, 1, 1024])\n",
      "2025-03-18 17:10:17,024 - __main__ - INFO - Forward pass completed.\n",
      "2025-03-18 17:10:17,029 - __main__ - WARNING - Forward called with input_ids=None\n",
      "2025-03-18 17:10:17,029 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([8, 1])\n",
      "2025-03-18 17:10:17,030 - __main__ - INFO - reversed_position_decoder_input_ids shape: torch.Size([8, 1])\n",
      "2025-03-18 17:10:17,031 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([8, 1, 1024])\n",
      "2025-03-18 17:10:17,031 - __main__ - INFO - position_decoder_input_ids shape: torch.Size([8, 1])\n",
      "2025-03-18 17:10:17,032 - __main__ - INFO - position_embeddings shape: torch.Size([8, 1, 1024])\n",
      "2025-03-18 17:10:17,033 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([8, 1, 1024])\n",
      "2025-03-18 17:10:17,086 - __main__ - INFO - Forward pass completed.\n",
      "2025-03-18 17:10:17,091 - __main__ - WARNING - Forward called with input_ids=None\n",
      "2025-03-18 17:10:17,092 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([8, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2]])\n",
      "tensor([[1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]])\n",
      "tensor([[0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1]])\n",
      "tensor([[1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [3],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0]])\n",
      "tensor([[1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 17:10:17,092 - __main__ - INFO - reversed_position_decoder_input_ids shape: torch.Size([8, 1])\n",
      "2025-03-18 17:10:17,094 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([8, 1, 1024])\n",
      "2025-03-18 17:10:17,094 - __main__ - INFO - position_decoder_input_ids shape: torch.Size([8, 1])\n",
      "2025-03-18 17:10:17,096 - __main__ - INFO - position_embeddings shape: torch.Size([8, 1, 1024])\n",
      "2025-03-18 17:10:17,096 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([8, 1, 1024])\n",
      "2025-03-18 17:10:17,153 - __main__ - INFO - Forward pass completed.\n",
      "2025-03-18 17:10:17,158 - __main__ - WARNING - Forward called with input_ids=None\n",
      "2025-03-18 17:10:17,159 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([8, 1])\n",
      "2025-03-18 17:10:17,159 - __main__ - INFO - reversed_position_decoder_input_ids shape: torch.Size([8, 1])\n",
      "2025-03-18 17:10:17,160 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([8, 1, 1024])\n",
      "2025-03-18 17:10:17,161 - __main__ - INFO - position_decoder_input_ids shape: torch.Size([8, 1])\n",
      "2025-03-18 17:10:17,162 - __main__ - INFO - position_embeddings shape: torch.Size([8, 1, 1024])\n",
      "2025-03-18 17:10:17,163 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([8, 1, 1024])\n",
      "2025-03-18 17:10:17,224 - __main__ - INFO - Forward pass completed.\n",
      "2025-03-18 17:10:17,229 - __main__ - WARNING - Forward called with input_ids=None\n",
      "2025-03-18 17:10:17,230 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([8, 1])\n",
      "2025-03-18 17:10:17,230 - __main__ - INFO - reversed_position_decoder_input_ids shape: torch.Size([8, 1])\n",
      "2025-03-18 17:10:17,231 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([8, 1, 1024])\n",
      "2025-03-18 17:10:17,232 - __main__ - INFO - position_decoder_input_ids shape: torch.Size([8, 1])\n",
      "2025-03-18 17:10:17,233 - __main__ - INFO - position_embeddings shape: torch.Size([8, 1, 1024])\n",
      "2025-03-18 17:10:17,234 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([8, 1, 1024])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1],\n",
      "        [3],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [2]])\n",
      "tensor([[1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]])\n",
      "tensor([[3],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1]])\n",
      "tensor([[1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]])\n",
      "tensor([[1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [3]])\n",
      "tensor([[1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 17:10:17,296 - __main__ - INFO - Forward pass completed.\n",
      "2025-03-18 17:10:17,301 - __main__ - WARNING - Forward called with input_ids=None\n",
      "2025-03-18 17:10:17,301 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([8, 1])\n",
      "2025-03-18 17:10:17,302 - __main__ - INFO - reversed_position_decoder_input_ids shape: torch.Size([8, 1])\n",
      "2025-03-18 17:10:17,303 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([8, 1, 1024])\n",
      "2025-03-18 17:10:17,304 - __main__ - INFO - position_decoder_input_ids shape: torch.Size([8, 1])\n",
      "2025-03-18 17:10:17,305 - __main__ - INFO - position_embeddings shape: torch.Size([8, 1, 1024])\n",
      "2025-03-18 17:10:17,305 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([8, 1, 1024])\n",
      "2025-03-18 17:10:17,371 - __main__ - INFO - Forward pass completed.\n",
      "2025-03-18 17:10:17,376 - __main__ - WARNING - Forward called with input_ids=None\n",
      "2025-03-18 17:10:17,377 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([8, 1])\n",
      "2025-03-18 17:10:17,377 - __main__ - INFO - reversed_position_decoder_input_ids shape: torch.Size([8, 1])\n",
      "2025-03-18 17:10:17,378 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([8, 1, 1024])\n",
      "2025-03-18 17:10:17,379 - __main__ - INFO - position_decoder_input_ids shape: torch.Size([8, 1])\n",
      "2025-03-18 17:10:17,380 - __main__ - INFO - position_embeddings shape: torch.Size([8, 1, 1024])\n",
      "2025-03-18 17:10:17,381 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([8, 1, 1024])\n",
      "2025-03-18 17:10:17,443 - __main__ - INFO - Forward pass completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]])\n",
      "tensor([[1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [3],\n",
      "        [4],\n",
      "        [3],\n",
      "        [0],\n",
      "        [1]])\n",
      "tensor([[1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]])\n",
      "Generated: FineFineFinefineFineFineTheFineFine\n"
     ]
    }
   ],
   "source": [
    "outputs = model.generate(input_ids=batch[\"input_ids\"],target_len=torch.tensor([5,3]), max_length=12)  # generate sequences\n",
    "print('Generated: {}'.format(tokenizer.decode(outputs[0], skip_special_tokens=True)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REpilotBartForGeneration test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    GenerationMixin,\n",
    "    BartConfig,\n",
    "    BartModel,\n",
    "    BartPreTrainedModel,                         \n",
    ")   \n",
    "\n",
    "def shift_tokens_right(input_ids: torch.Tensor, pad_token_id: int, decoder_start_token_id: int):\n",
    "    \"\"\"\n",
    "    Shift input ids one token to the right.\n",
    "    \"\"\"\n",
    "    shifted_input_ids = input_ids.new_zeros(input_ids.shape)\n",
    "    shifted_input_ids[:, 1:] = input_ids[:, :-1].clone()\n",
    "    shifted_input_ids[:, 0] = decoder_start_token_id\n",
    "\n",
    "    if pad_token_id is None:\n",
    "        raise ValueError(\"self.model.config.pad_token_id has to be defined.\")\n",
    "    # replace possible -100 values in labels by `pad_token_id`\n",
    "    shifted_input_ids.masked_fill_(shifted_input_ids == -100, pad_token_id)\n",
    "\n",
    "    return shifted_input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 14:56:14,328 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /facebook/bart-large/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "2025-03-18 14:56:14,559 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /facebook/bart-large/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-03-18 14:56:14,696 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /facebook/bart-large/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-03-18 14:56:14,810 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /facebook/bart-large/resolve/main/model.safetensors HTTP/1.1\" 404 0\n",
      "2025-03-18 14:56:15,222 - __main__ - INFO - Iitialized sinusoidal position embedding successfully.\n",
      "Some weights of RepilotBartForConditionalGeneration were not initialized from the model checkpoint at facebook/bart-large and are newly initialized: ['embed_reverse_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-03-18 14:56:15,667 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /facebook/bart-large/resolve/main/generation_config.json HTTP/1.1\" 404 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class RepilotBartForConditionalGeneration(BartPreTrainedModel, GenerationMixin):\n",
    "    base_model_prefix = \"model\"\n",
    "    _tied_weights_keys = [\"encoder.embed_tokens.weight\", \"decoder.embed_tokens.weight\", \"lm_head.weight\"]\n",
    "    _keys_to_ignore_on_load_missing = [\"final_logits_bias\"]\n",
    "\n",
    "    def __init__(self, config: BartConfig):\n",
    "        super().__init__(config)\n",
    "        self.model = BartModel(config)\n",
    "        self.embed_reverse_positions = self._create_sinusoidal_position_embedding()\n",
    "        self.register_buffer(\"final_logits_bias\", torch.zeros((1, self.model.shared.num_embeddings)))\n",
    "        self.lm_head = nn.Linear(config.d_model, self.model.shared.num_embeddings, bias=False)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "    \n",
    "    def _create_sinusoidal_position_embedding(self)->torch.nn.Embedding:\n",
    "        \"\"\"Creates sinusoidal reversed position embeddings.\"\"\"\n",
    "        d_model = self.config.d_model\n",
    "        max_len = self.config.max_position_embeddings\n",
    "        padding_idx = self.config.pad_token_id\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(-2 * (torch.arange(0, d_model) // 2) / d_model * math.log(10000.0))\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term[0::2])\n",
    "        pe[:, 1::2] = torch.cos(position * div_term[1::2])\n",
    "\n",
    "        embedding = nn.Embedding(num_embeddings=max_len,\n",
    "                                embedding_dim=d_model,\n",
    "                                padding_idx=padding_idx,\n",
    "                                _weight=pe,\n",
    "                                _freeze=True)\n",
    "        logger.info(\"Iitialized sinusoidal position embedding successfully.\")\n",
    "        return embedding\n",
    "\n",
    "    def get_encoder(self):\n",
    "        return self.model.get_encoder()\n",
    "\n",
    "    def get_decoder(self):\n",
    "        return self.model.get_decoder()\n",
    "\n",
    "    def resize_token_embeddings(self, new_num_tokens: int, pad_to_multiple_of: Optional[int] = None) -> nn.Embedding:\n",
    "        new_embeddings = super().resize_token_embeddings(new_num_tokens, pad_to_multiple_of)\n",
    "        self._resize_final_logits_bias(new_embeddings.weight.shape[0])\n",
    "        return new_embeddings\n",
    "\n",
    "    def _resize_final_logits_bias(self, new_num_tokens: int) -> None:\n",
    "        old_num_tokens = self.final_logits_bias.shape[-1]\n",
    "        if new_num_tokens <= old_num_tokens:\n",
    "            new_bias = self.final_logits_bias[:, :new_num_tokens]\n",
    "        else:\n",
    "            extra_bias = torch.zeros((1, new_num_tokens - old_num_tokens), device=self.final_logits_bias.device)\n",
    "            new_bias = torch.cat([self.final_logits_bias, extra_bias], dim=1)\n",
    "        self.register_buffer(\"final_logits_bias\", new_bias)\n",
    "\n",
    "    def get_output_embeddings(self):\n",
    "        return self.lm_head\n",
    "\n",
    "    def set_output_embeddings(self, new_embeddings):\n",
    "        self.lm_head = new_embeddings\n",
    "    \n",
    "    def _get_reverse_position_decoder_ids(self, decoder_input_ids:torch.LongTensor, target_len:Optional[torch.Tensor]=None, gaussian_noise=True)->torch.LongTensor:\n",
    "        \"\"\"Computes reversed position indices for the decoder inputs.\"\"\"\n",
    "        \n",
    "        mask = ~torch.isin(decoder_input_ids,torch.tensor([self.config.pad_token_id]))\n",
    "\n",
    "        reversed_position_input  = torch.ones(mask.shape) * mask \n",
    "        \n",
    "        if target_len is None:\n",
    "            reversed_position_input = torch.flip(torch.flip(reversed_position_input , dims=(1,)).cumsum(dim=1), dims=(1,))\n",
    "            logger.debug(f\"Shape of reversed_position_input {reversed_position_input.shape}\")\n",
    "\n",
    "        else:\n",
    "            for k in range(decoder_input_ids.size(-1)):\n",
    "                reversed_position_input[:,k] = F.relu(target_len -k)\n",
    "                logger.debug(f\"reversed_position_input[:,{k}] {reversed_position_input[:,k]}\")\n",
    "\n",
    "        if gaussian_noise:\n",
    "            normal_round = torch.randn(reversed_position_input.shape) * mask\n",
    "        else:\n",
    "            normal_round = 0\n",
    "\n",
    "        return torch.abs(torch.round(reversed_position_input  + normal_round)).to(torch.long)\n",
    "    \n",
    "    def _get_position_decoder_ids(self, decoder_input_ids:torch.LongTensor)->torch.LongTensor:\n",
    "        \"\"\"Computes position indices for the decoder inputs.\"\"\"\n",
    "        \n",
    "        mask = ~torch.isin(decoder_input_ids,torch.tensor([self.config.pad_token_id]))\n",
    "\n",
    "        position_decoder_input_ids  = torch.ones(mask.shape) * mask \n",
    "        \n",
    "        return position_decoder_input_ids.cumsum(dim=1).to(torch.long)\n",
    "    \n",
    "\n",
    "    # @add_start_docstrings_to_model_forward(BART_INPUTS_DOCSTRING)\n",
    "    @replace_return_docstrings(output_type=Seq2SeqLMOutput, config_class=_CONFIG_FOR_DOC)\n",
    "    # @add_end_docstrings(BART_GENERATION_EXAMPLE)\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: torch.LongTensor = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        decoder_input_ids: Optional[torch.LongTensor] = None,\n",
    "        decoder_attention_mask: Optional[torch.LongTensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        decoder_head_mask: Optional[torch.Tensor] = None,\n",
    "        cross_attn_head_mask: Optional[torch.Tensor] = None,\n",
    "        encoder_outputs: Optional[List[torch.FloatTensor]] = None,\n",
    "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        decoder_inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        labels: Optional[torch.LongTensor] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "        target_len:Optional[torch.Tensor]=None,\n",
    "    ) -> Union[Tuple, Seq2SeqLMOutput]:\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
    "            Labels for computing the masked language modeling loss. Indices should either be in `[0, ...,\n",
    "            config.vocab_size]` or -100 (see `input_ids` docstring). Tokens with indices set to `-100` are ignored\n",
    "            (masked), the loss is only computed for the tokens with labels in `[0, ..., config.vocab_size]`.\n",
    "\n",
    "        Returns:\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        if labels is not None:\n",
    "            if use_cache:\n",
    "                logger.warning(\"The `use_cache` argument is changed to `False` since `labels` is provided.\")\n",
    "            use_cache = False\n",
    "            if decoder_input_ids is None and decoder_inputs_embeds is None:\n",
    "                decoder_input_ids = shift_tokens_right(\n",
    "                    labels, self.config.pad_token_id, self.config.decoder_start_token_id\n",
    "                )\n",
    "\n",
    "        if decoder_input_ids is not None:\n",
    "\n",
    "            # Get reversed position indices\n",
    "            reversed_position_input_ids = self._get_reverse_position_decoder_ids(decoder_input_ids, target_len)\n",
    "            logger.info(f\"reversed_position_input_ids shape: {reversed_position_input_ids.shape}\")\n",
    "            \n",
    "            # Compute reversed position embeddings\n",
    "            reversed_position_embeddings = self.embed_reverse_positions(reversed_position_input_ids)\n",
    "            logger.info(f\"reversed_position_embeddings shape: {reversed_position_embeddings.shape}\")\n",
    "\n",
    "            # Get position indices\n",
    "            position_input_ids = self._get_position_decoder_ids(decoder_input_ids)\n",
    "            logger.info(f\"position_input_ids shape: {position_input_ids.shape}\")\n",
    "            \n",
    "            # Compute position embeddings\n",
    "            position_embeddings = self.model.decoder.embed_positions(position_input_ids)\n",
    "            logger.info(f\"position_embeddings shape: {position_embeddings.shape}\")\n",
    "\n",
    "            # Compute standard token embeddings\n",
    "            decoder_inputs_embeds = self.model.decoder.embed_tokens(decoder_input_ids) + reversed_position_embeddings + position_embeddings\n",
    "            logger.debug(f\"decoder_inputs_embeds shape: {decoder_inputs_embeds.shape}\")\n",
    "\n",
    "            decoder_input_ids = None\n",
    "   \n",
    "\n",
    "        outputs = self.model(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            decoder_input_ids=decoder_input_ids,\n",
    "            encoder_outputs=encoder_outputs,\n",
    "            decoder_attention_mask=decoder_attention_mask,\n",
    "            head_mask=head_mask,\n",
    "            decoder_head_mask=decoder_head_mask,\n",
    "            cross_attn_head_mask=cross_attn_head_mask,\n",
    "            past_key_values=past_key_values,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            decoder_inputs_embeds=decoder_inputs_embeds,\n",
    "            use_cache=use_cache,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        lm_logits = self.lm_head(outputs[0])\n",
    "        lm_logits = lm_logits + self.final_logits_bias.to(lm_logits.device)\n",
    "\n",
    "        masked_lm_loss = None\n",
    "        if labels is not None:\n",
    "            labels = labels.to(lm_logits.device)\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            masked_lm_loss = loss_fct(lm_logits.view(-1, self.config.vocab_size), labels.view(-1))\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (lm_logits,) + outputs[1:]\n",
    "            return ((masked_lm_loss,) + output) if masked_lm_loss is not None else output\n",
    "\n",
    "        return Seq2SeqLMOutput(\n",
    "            loss=masked_lm_loss,\n",
    "            logits=lm_logits,\n",
    "            past_key_values=outputs.past_key_values,\n",
    "            decoder_hidden_states=outputs.decoder_hidden_states,\n",
    "            decoder_attentions=outputs.decoder_attentions,\n",
    "            cross_attentions=outputs.cross_attentions,\n",
    "            encoder_last_hidden_state=outputs.encoder_last_hidden_state,\n",
    "            encoder_hidden_states=outputs.encoder_hidden_states,\n",
    "            encoder_attentions=outputs.encoder_attentions,\n",
    "        )\n",
    "\n",
    "    def prepare_inputs_for_generation(\n",
    "        self,\n",
    "        decoder_input_ids,\n",
    "        past_key_values=None,\n",
    "        attention_mask=None,\n",
    "        decoder_attention_mask=None,\n",
    "        head_mask=None,\n",
    "        decoder_head_mask=None,\n",
    "        cross_attn_head_mask=None,\n",
    "        use_cache=None,\n",
    "        encoder_outputs=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        # cut decoder_input_ids if past_key_values is used\n",
    "        if past_key_values is not None:\n",
    "            past_length = past_key_values[0][0].shape[2]\n",
    "\n",
    "            # Some generation methods already pass only the last input ID\n",
    "            if decoder_input_ids.shape[1] > past_length:\n",
    "                remove_prefix_length = past_length\n",
    "            else:\n",
    "                # Default to old behavior: keep only final ID\n",
    "                remove_prefix_length = decoder_input_ids.shape[1] - 1\n",
    "\n",
    "            decoder_input_ids = decoder_input_ids[:, remove_prefix_length:]\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": None,  # encoder_outputs is defined. input_ids not needed\n",
    "            \"encoder_outputs\": encoder_outputs,\n",
    "            \"past_key_values\": past_key_values,\n",
    "            \"decoder_input_ids\": decoder_input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"decoder_attention_mask\": decoder_attention_mask,\n",
    "            \"head_mask\": head_mask,\n",
    "            \"decoder_head_mask\": decoder_head_mask,\n",
    "            \"cross_attn_head_mask\": cross_attn_head_mask,\n",
    "            \"use_cache\": use_cache,  # change this to avoid caching (presumably for debugging)\n",
    "        }\n",
    "\n",
    "    def prepare_decoder_input_ids_from_labels(self, labels: torch.Tensor):\n",
    "        return shift_tokens_right(labels, self.config.pad_token_id, self.config.decoder_start_token_id)\n",
    "\n",
    "    @staticmethod\n",
    "    def _reorder_cache(past_key_values, beam_idx):\n",
    "        reordered_past = ()\n",
    "        for layer_past in past_key_values:\n",
    "            # cached cross_attention states don't have to be reordered -> they are always the same\n",
    "            reordered_past += (\n",
    "                tuple(past_state.index_select(0, beam_idx.to(past_state.device)) for past_state in layer_past[:2])\n",
    "                + layer_past[2:],\n",
    "            )\n",
    "        return reordered_past\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(_CHECKPOINT_FOR_DOC, clean_up_tokenization_spaces=True)\n",
    "model = RepilotBartForConditionalGeneration.from_pretrained(_CHECKPOINT_FOR_DOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good', 'great', 'all', 'really', 'very']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TXT = \"My friends are <mask> but they eat too many carbs.\"\n",
    "input_ids = tokenizer.batch_encode_plus([TXT], return_tensors='pt')['input_ids']\n",
    "logits = model(input_ids)[0]\n",
    "masked_index = (input_ids[0] == tokenizer.mask_token_id).nonzero().item()\n",
    "probs = logits[0, masked_index].softmax(dim=0)\n",
    "values, predictions = probs.topk(5)\n",
    "tokenizer.decode(predictions).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 14:56:21,280 - __main__ - DEBUG - reversed_position_input[:,0] tensor([64., 48., 57., 46.])\n",
      "2025-03-18 14:56:21,281 - __main__ - DEBUG - reversed_position_input[:,1] tensor([63., 47., 56., 45.])\n",
      "2025-03-18 14:56:21,283 - __main__ - DEBUG - reversed_position_input[:,2] tensor([62., 46., 55., 44.])\n",
      "2025-03-18 14:56:21,284 - __main__ - DEBUG - reversed_position_input[:,3] tensor([61., 45., 54., 43.])\n",
      "2025-03-18 14:56:21,285 - __main__ - DEBUG - reversed_position_input[:,4] tensor([60., 44., 53., 42.])\n",
      "2025-03-18 14:56:21,286 - __main__ - DEBUG - reversed_position_input[:,5] tensor([59., 43., 52., 41.])\n",
      "2025-03-18 14:56:21,287 - __main__ - DEBUG - reversed_position_input[:,6] tensor([58., 42., 51., 40.])\n",
      "2025-03-18 14:56:21,288 - __main__ - DEBUG - reversed_position_input[:,7] tensor([57., 41., 50., 39.])\n",
      "2025-03-18 14:56:21,289 - __main__ - DEBUG - reversed_position_input[:,8] tensor([56., 40., 49., 38.])\n",
      "2025-03-18 14:56:21,290 - __main__ - DEBUG - reversed_position_input[:,9] tensor([55., 39., 48., 37.])\n",
      "2025-03-18 14:56:21,291 - __main__ - DEBUG - reversed_position_input[:,10] tensor([54., 38., 47., 36.])\n",
      "2025-03-18 14:56:21,291 - __main__ - DEBUG - reversed_position_input[:,11] tensor([53., 37., 46., 35.])\n",
      "2025-03-18 14:56:21,292 - __main__ - DEBUG - reversed_position_input[:,12] tensor([52., 36., 45., 34.])\n",
      "2025-03-18 14:56:21,293 - __main__ - DEBUG - reversed_position_input[:,13] tensor([51., 35., 44., 33.])\n",
      "2025-03-18 14:56:21,294 - __main__ - DEBUG - reversed_position_input[:,14] tensor([50., 34., 43., 32.])\n",
      "2025-03-18 14:56:21,295 - __main__ - DEBUG - reversed_position_input[:,15] tensor([49., 33., 42., 31.])\n",
      "2025-03-18 14:56:21,296 - __main__ - DEBUG - reversed_position_input[:,16] tensor([48., 32., 41., 30.])\n",
      "2025-03-18 14:56:21,297 - __main__ - DEBUG - reversed_position_input[:,17] tensor([47., 31., 40., 29.])\n",
      "2025-03-18 14:56:21,299 - __main__ - DEBUG - reversed_position_input[:,18] tensor([46., 30., 39., 28.])\n",
      "2025-03-18 14:56:21,300 - __main__ - DEBUG - reversed_position_input[:,19] tensor([45., 29., 38., 27.])\n",
      "2025-03-18 14:56:21,301 - __main__ - DEBUG - reversed_position_input[:,20] tensor([44., 28., 37., 26.])\n",
      "2025-03-18 14:56:21,302 - __main__ - DEBUG - reversed_position_input[:,21] tensor([43., 27., 36., 25.])\n",
      "2025-03-18 14:56:21,303 - __main__ - DEBUG - reversed_position_input[:,22] tensor([42., 26., 35., 24.])\n",
      "2025-03-18 14:56:21,305 - __main__ - DEBUG - reversed_position_input[:,23] tensor([41., 25., 34., 23.])\n",
      "2025-03-18 14:56:21,306 - __main__ - DEBUG - reversed_position_input[:,24] tensor([40., 24., 33., 22.])\n",
      "2025-03-18 14:56:21,307 - __main__ - DEBUG - reversed_position_input[:,25] tensor([39., 23., 32., 21.])\n",
      "2025-03-18 14:56:21,308 - __main__ - DEBUG - reversed_position_input[:,26] tensor([38., 22., 31., 20.])\n",
      "2025-03-18 14:56:21,309 - __main__ - DEBUG - reversed_position_input[:,27] tensor([37., 21., 30., 19.])\n",
      "2025-03-18 14:56:21,310 - __main__ - DEBUG - reversed_position_input[:,28] tensor([36., 20., 29., 18.])\n",
      "2025-03-18 14:56:21,311 - __main__ - DEBUG - reversed_position_input[:,29] tensor([35., 19., 28., 17.])\n",
      "2025-03-18 14:56:21,312 - __main__ - DEBUG - reversed_position_input[:,30] tensor([34., 18., 27., 16.])\n",
      "2025-03-18 14:56:21,313 - __main__ - DEBUG - reversed_position_input[:,31] tensor([33., 17., 26., 15.])\n",
      "2025-03-18 14:56:21,314 - __main__ - DEBUG - reversed_position_input[:,32] tensor([32., 16., 25., 14.])\n",
      "2025-03-18 14:56:21,315 - __main__ - DEBUG - reversed_position_input[:,33] tensor([31., 15., 24., 13.])\n",
      "2025-03-18 14:56:21,316 - __main__ - DEBUG - reversed_position_input[:,34] tensor([30., 14., 23., 12.])\n",
      "2025-03-18 14:56:21,317 - __main__ - DEBUG - reversed_position_input[:,35] tensor([29., 13., 22., 11.])\n",
      "2025-03-18 14:56:21,319 - __main__ - DEBUG - reversed_position_input[:,36] tensor([28., 12., 21., 10.])\n",
      "2025-03-18 14:56:21,320 - __main__ - DEBUG - reversed_position_input[:,37] tensor([27., 11., 20.,  9.])\n",
      "2025-03-18 14:56:21,321 - __main__ - DEBUG - reversed_position_input[:,38] tensor([26., 10., 19.,  8.])\n",
      "2025-03-18 14:56:21,322 - __main__ - DEBUG - reversed_position_input[:,39] tensor([25.,  9., 18.,  7.])\n",
      "2025-03-18 14:56:21,323 - __main__ - DEBUG - reversed_position_input[:,40] tensor([24.,  8., 17.,  6.])\n",
      "2025-03-18 14:56:21,324 - __main__ - DEBUG - reversed_position_input[:,41] tensor([23.,  7., 16.,  5.])\n",
      "2025-03-18 14:56:21,325 - __main__ - DEBUG - reversed_position_input[:,42] tensor([22.,  6., 15.,  4.])\n",
      "2025-03-18 14:56:21,326 - __main__ - DEBUG - reversed_position_input[:,43] tensor([21.,  5., 14.,  3.])\n",
      "2025-03-18 14:56:21,327 - __main__ - DEBUG - reversed_position_input[:,44] tensor([20.,  4., 13.,  2.])\n",
      "2025-03-18 14:56:21,328 - __main__ - DEBUG - reversed_position_input[:,45] tensor([19.,  3., 12.,  1.])\n",
      "2025-03-18 14:56:21,329 - __main__ - DEBUG - reversed_position_input[:,46] tensor([18.,  2., 11.,  0.])\n",
      "2025-03-18 14:56:21,330 - __main__ - DEBUG - reversed_position_input[:,47] tensor([17.,  1., 10.,  0.])\n",
      "2025-03-18 14:56:21,331 - __main__ - DEBUG - reversed_position_input[:,48] tensor([16.,  0.,  9.,  0.])\n",
      "2025-03-18 14:56:21,332 - __main__ - DEBUG - reversed_position_input[:,49] tensor([15.,  0.,  8.,  0.])\n",
      "2025-03-18 14:56:21,333 - __main__ - DEBUG - reversed_position_input[:,50] tensor([14.,  0.,  7.,  0.])\n",
      "2025-03-18 14:56:21,334 - __main__ - DEBUG - reversed_position_input[:,51] tensor([13.,  0.,  6.,  0.])\n",
      "2025-03-18 14:56:21,335 - __main__ - DEBUG - reversed_position_input[:,52] tensor([12.,  0.,  5.,  0.])\n",
      "2025-03-18 14:56:21,336 - __main__ - DEBUG - reversed_position_input[:,53] tensor([11.,  0.,  4.,  0.])\n",
      "2025-03-18 14:56:21,338 - __main__ - DEBUG - reversed_position_input[:,54] tensor([10.,  0.,  3.,  0.])\n",
      "2025-03-18 14:56:21,339 - __main__ - DEBUG - reversed_position_input[:,55] tensor([9., 0., 2., 0.])\n",
      "2025-03-18 14:56:21,340 - __main__ - DEBUG - reversed_position_input[:,56] tensor([8., 0., 1., 0.])\n",
      "2025-03-18 14:56:21,341 - __main__ - DEBUG - reversed_position_input[:,57] tensor([7., 0., 0., 0.])\n",
      "2025-03-18 14:56:21,342 - __main__ - DEBUG - reversed_position_input[:,58] tensor([6., 0., 0., 0.])\n",
      "2025-03-18 14:56:21,343 - __main__ - DEBUG - reversed_position_input[:,59] tensor([5., 0., 0., 0.])\n",
      "2025-03-18 14:56:21,344 - __main__ - DEBUG - reversed_position_input[:,60] tensor([4., 0., 0., 0.])\n",
      "2025-03-18 14:56:21,345 - __main__ - DEBUG - reversed_position_input[:,61] tensor([3., 0., 0., 0.])\n",
      "2025-03-18 14:56:21,346 - __main__ - DEBUG - reversed_position_input[:,62] tensor([2., 0., 0., 0.])\n",
      "2025-03-18 14:56:21,346 - __main__ - DEBUG - reversed_position_input[:,63] tensor([1., 0., 0., 0.])\n",
      "2025-03-18 14:56:21,347 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 64])\n",
      "2025-03-18 14:56:21,348 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 64, 1024])\n",
      "2025-03-18 14:56:21,348 - __main__ - INFO - position_input_ids shape: torch.Size([4, 64])\n",
      "2025-03-18 14:56:21,349 - __main__ - INFO - position_embeddings shape: torch.Size([4, 64, 1024])\n",
      "2025-03-18 14:56:21,350 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 64, 1024])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    batch.pop('input_len')\n",
    "    break\n",
    "\n",
    "output = model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivanhoe/Bureau/length-control-for-summarization/.venv/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:601: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "2025-03-18 15:01:27,637 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([4, 1])\n",
      "2025-03-18 15:01:27,637 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:27,638 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:27,639 - __main__ - INFO - position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:27,639 - __main__ - INFO - position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:27,640 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:27,706 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([4, 1])\n",
      "2025-03-18 15:01:27,707 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:27,708 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:27,709 - __main__ - INFO - position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:27,709 - __main__ - INFO - position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:27,710 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:27,767 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([4, 1])\n",
      "2025-03-18 15:01:27,768 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:27,768 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:27,769 - __main__ - INFO - position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:27,770 - __main__ - INFO - position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:27,770 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:27,827 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([4, 1])\n",
      "2025-03-18 15:01:27,828 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:27,829 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:27,829 - __main__ - INFO - position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:27,830 - __main__ - INFO - position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:27,831 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:27,882 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([4, 1])\n",
      "2025-03-18 15:01:27,883 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:27,884 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:27,884 - __main__ - INFO - position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:27,885 - __main__ - INFO - position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:27,886 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:27,937 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([4, 1])\n",
      "2025-03-18 15:01:27,937 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:27,938 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:27,939 - __main__ - INFO - position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:27,939 - __main__ - INFO - position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:27,940 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:27,999 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([4, 1])\n",
      "2025-03-18 15:01:28,000 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:28,001 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:28,001 - __main__ - INFO - position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:28,002 - __main__ - INFO - position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:28,003 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:28,076 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([4, 1])\n",
      "2025-03-18 15:01:28,077 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:28,078 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:28,079 - __main__ - INFO - position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:28,080 - __main__ - INFO - position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:28,080 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:28,188 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([4, 1])\n",
      "2025-03-18 15:01:28,189 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:28,189 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:28,190 - __main__ - INFO - position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:28,191 - __main__ - INFO - position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:28,192 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:28,320 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([4, 1])\n",
      "2025-03-18 15:01:28,321 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:28,322 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:28,323 - __main__ - INFO - position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:28,324 - __main__ - INFO - position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:28,324 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:28,413 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([4, 1])\n",
      "2025-03-18 15:01:28,413 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:28,414 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:28,415 - __main__ - INFO - position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:28,415 - __main__ - INFO - position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:28,416 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:28,472 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([4, 1])\n",
      "2025-03-18 15:01:28,473 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:28,474 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:28,474 - __main__ - INFO - position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:28,475 - __main__ - INFO - position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:28,475 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:28,527 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([4, 1])\n",
      "2025-03-18 15:01:28,528 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:28,528 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:28,529 - __main__ - INFO - position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:28,530 - __main__ - INFO - position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:28,530 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:28,582 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([4, 1])\n",
      "2025-03-18 15:01:28,583 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:28,584 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:28,584 - __main__ - INFO - position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:28,585 - __main__ - INFO - position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:28,585 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:28,638 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([4, 1])\n",
      "2025-03-18 15:01:28,639 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:28,639 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:28,640 - __main__ - INFO - position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:28,641 - __main__ - INFO - position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:28,641 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:28,700 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([4, 1])\n",
      "2025-03-18 15:01:28,700 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:28,701 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:28,702 - __main__ - INFO - position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:28,702 - __main__ - INFO - position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:28,703 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:28,765 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([4, 1])\n",
      "2025-03-18 15:01:28,766 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:28,766 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:28,767 - __main__ - INFO - position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:28,767 - __main__ - INFO - position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:28,768 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:28,829 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([4, 1])\n",
      "2025-03-18 15:01:28,830 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:28,830 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:28,831 - __main__ - INFO - position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:28,832 - __main__ - INFO - position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:28,833 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:28,895 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([4, 1])\n",
      "2025-03-18 15:01:28,896 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:28,897 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:28,897 - __main__ - INFO - position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:28,898 - __main__ - INFO - position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:28,899 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:28,956 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([4, 1])\n",
      "2025-03-18 15:01:28,957 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:28,957 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:28,958 - __main__ - INFO - position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:28,958 - __main__ - INFO - position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:28,959 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:29,017 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([4, 1])\n",
      "2025-03-18 15:01:29,018 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:29,018 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:29,019 - __main__ - INFO - position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:29,019 - __main__ - INFO - position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:29,020 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:29,078 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([4, 1])\n",
      "2025-03-18 15:01:29,079 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:29,079 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:29,080 - __main__ - INFO - position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:29,081 - __main__ - INFO - position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:29,081 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:29,142 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([4, 1])\n",
      "2025-03-18 15:01:29,143 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:29,144 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:29,144 - __main__ - INFO - position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:29,145 - __main__ - INFO - position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:29,146 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:29,207 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([4, 1])\n",
      "2025-03-18 15:01:29,208 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:29,209 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:29,210 - __main__ - INFO - position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:29,210 - __main__ - INFO - position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:29,211 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:29,271 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([4, 1])\n",
      "2025-03-18 15:01:29,272 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:29,273 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:29,273 - __main__ - INFO - position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:29,274 - __main__ - INFO - position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:29,274 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:29,332 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([4, 1])\n",
      "2025-03-18 15:01:29,333 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:29,334 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:29,334 - __main__ - INFO - position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:29,335 - __main__ - INFO - position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:29,336 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:29,394 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([4, 1])\n",
      "2025-03-18 15:01:29,395 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:29,395 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:29,396 - __main__ - INFO - position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:29,397 - __main__ - INFO - position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:29,398 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:29,456 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([4, 1])\n",
      "2025-03-18 15:01:29,457 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:29,458 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:29,458 - __main__ - INFO - position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:29,459 - __main__ - INFO - position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:29,460 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:29,519 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([4, 1])\n",
      "2025-03-18 15:01:29,519 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:29,520 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:29,521 - __main__ - INFO - position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:29,521 - __main__ - INFO - position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:29,522 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:29,584 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([4, 1])\n",
      "2025-03-18 15:01:29,584 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:29,585 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:29,585 - __main__ - INFO - position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:29,586 - __main__ - INFO - position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:29,586 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:29,652 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([4, 1])\n",
      "2025-03-18 15:01:29,653 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:29,653 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:29,654 - __main__ - INFO - position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:29,654 - __main__ - INFO - position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:29,655 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:29,711 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([4, 1])\n",
      "2025-03-18 15:01:29,712 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:29,712 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:29,713 - __main__ - INFO - position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:29,714 - __main__ - INFO - position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:29,714 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:29,774 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([4, 1])\n",
      "2025-03-18 15:01:29,774 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:29,775 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:29,776 - __main__ - INFO - position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:29,777 - __main__ - INFO - position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:29,777 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:29,834 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([4, 1])\n",
      "2025-03-18 15:01:29,835 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:29,835 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:29,836 - __main__ - INFO - position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:29,836 - __main__ - INFO - position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:29,837 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:29,898 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([4, 1])\n",
      "2025-03-18 15:01:29,899 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:29,899 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:29,900 - __main__ - INFO - position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:29,901 - __main__ - INFO - position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:29,902 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:29,965 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([4, 1])\n",
      "2025-03-18 15:01:29,966 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:29,967 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:29,967 - __main__ - INFO - position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:29,968 - __main__ - INFO - position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:29,969 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:30,030 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([4, 1])\n",
      "2025-03-18 15:01:30,031 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:30,031 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:30,032 - __main__ - INFO - position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:30,033 - __main__ - INFO - position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:30,033 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:30,099 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([4, 1])\n",
      "2025-03-18 15:01:30,100 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:30,100 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:30,101 - __main__ - INFO - position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:30,101 - __main__ - INFO - position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:30,102 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:30,160 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([4, 1])\n",
      "2025-03-18 15:01:30,161 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:30,161 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:30,162 - __main__ - INFO - position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:30,163 - __main__ - INFO - position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:30,164 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:30,219 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([4, 1])\n",
      "2025-03-18 15:01:30,219 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:30,220 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:30,221 - __main__ - INFO - position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:30,221 - __main__ - INFO - position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:30,222 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:30,283 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([4, 1])\n",
      "2025-03-18 15:01:30,284 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:30,285 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:30,285 - __main__ - INFO - position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:30,286 - __main__ - INFO - position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:30,287 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:30,347 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([4, 1])\n",
      "2025-03-18 15:01:30,348 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:30,348 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:30,349 - __main__ - INFO - position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:30,349 - __main__ - INFO - position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:30,350 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:30,409 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([4, 1])\n",
      "2025-03-18 15:01:30,410 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:30,410 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:30,411 - __main__ - INFO - position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:30,412 - __main__ - INFO - position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:30,412 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:30,472 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([4, 1])\n",
      "2025-03-18 15:01:30,472 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:30,473 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:30,474 - __main__ - INFO - position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:30,474 - __main__ - INFO - position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:30,475 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:30,537 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([4, 1])\n",
      "2025-03-18 15:01:30,538 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:30,539 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:30,539 - __main__ - INFO - position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:30,540 - __main__ - INFO - position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:30,541 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:30,604 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([4, 1])\n",
      "2025-03-18 15:01:30,605 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:30,606 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:30,607 - __main__ - INFO - position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:30,607 - __main__ - INFO - position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:30,608 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:30,672 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([4, 1])\n",
      "2025-03-18 15:01:30,673 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:30,674 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:30,674 - __main__ - INFO - position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:30,675 - __main__ - INFO - position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:30,675 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:30,740 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([4, 1])\n",
      "2025-03-18 15:01:30,740 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:30,741 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:30,742 - __main__ - INFO - position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:30,742 - __main__ - INFO - position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:30,743 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:30,806 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([4, 1])\n",
      "2025-03-18 15:01:30,807 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:30,807 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:30,808 - __main__ - INFO - position_input_ids shape: torch.Size([4, 1])\n",
      "2025-03-18 15:01:30,808 - __main__ - INFO - position_embeddings shape: torch.Size([4, 1, 1024])\n",
      "2025-03-18 15:01:30,809 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([4, 1, 1024])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated: LegalLegalLegallegalLegalLegalMyLegalLegalPoliticalLegalLegal10LegalLegalPersonalLegalLegalSocialLegalLegalILegalLegalCourtLegalLegalSexLegalLegal\"LegalLegalMilitaryLegalLegalHappyLegalLegal.LegalLegalReadLegalLegalSexualLegal\n"
     ]
    }
   ],
   "source": [
    "input_context = 'Legal My neighbor is'  # \"Legal\" is one of the control codes for ctrl\n",
    "input_ids = tokenizer.encode(input_context, return_tensors='pt')  # encode input context\n",
    "outputs = model.generate(input_ids=input_ids, max_length=50, temperature=0.7, repetition_penalty=1.2, target_len=torch.tensor([3]))  # generate sequences\n",
    "print('Generated: {}'.format(tokenizer.decode(outputs[0], skip_special_tokens=True)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 15:03:17,740 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:17,741 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:17,741 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:17,742 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:17,743 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:17,744 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:20,043 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:20,043 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:20,044 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:20,044 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:20,045 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:20,046 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:20,159 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:20,159 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:20,160 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:20,161 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:20,161 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:20,162 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:20,283 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:20,283 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:20,284 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:20,284 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:20,285 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:20,286 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:20,400 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:20,401 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:20,402 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:20,402 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:20,403 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:20,404 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:20,535 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:20,536 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:20,536 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:20,537 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:20,537 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:20,538 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:20,649 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:20,650 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:20,651 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:20,651 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:20,652 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:20,652 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:20,777 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:20,778 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:20,779 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:20,779 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:20,780 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:20,781 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:20,895 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:20,896 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:20,897 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:20,898 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:20,898 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:20,899 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:21,024 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:21,024 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:21,025 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:21,026 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:21,026 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:21,027 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:21,166 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:21,167 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:21,167 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:21,168 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:21,169 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:21,169 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:21,304 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:21,305 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:21,305 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:21,306 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:21,306 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:21,307 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:21,429 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:21,430 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:21,431 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:21,431 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:21,432 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:21,433 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:21,571 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:21,572 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:21,572 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:21,573 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:21,573 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:21,574 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:21,707 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:21,708 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:21,708 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:21,709 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:21,710 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:21,710 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:21,836 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:21,837 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:21,838 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:21,839 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:21,839 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:21,840 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:21,963 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:21,964 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:21,965 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:21,965 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:21,966 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:21,967 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:22,093 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:22,094 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:22,094 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:22,095 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:22,096 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:22,097 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:22,225 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:22,226 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:22,226 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:22,227 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:22,228 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:22,228 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:22,364 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:22,365 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:22,365 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:22,366 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:22,367 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:22,367 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:22,484 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:22,485 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:22,485 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:22,486 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:22,486 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:22,487 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:22,603 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:22,603 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:22,604 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:22,605 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:22,605 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:22,606 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:22,735 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:22,735 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:22,736 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:22,737 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:22,737 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:22,738 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:22,870 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:22,871 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:22,872 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:22,872 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:22,873 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:22,874 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:22,992 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:22,993 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:22,993 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:22,994 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:22,995 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:22,995 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:23,119 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:23,120 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:23,120 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:23,121 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:23,121 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:23,122 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:23,246 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:23,247 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:23,247 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:23,248 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:23,248 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:23,249 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:23,387 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:23,387 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:23,388 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:23,389 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:23,389 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:23,390 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:23,512 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:23,513 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:23,513 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:23,514 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:23,515 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:23,515 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:23,636 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:23,637 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:23,637 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:23,638 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:23,638 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:23,639 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:23,763 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:23,763 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:23,764 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:23,764 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:23,765 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:23,766 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:23,900 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:23,901 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:23,902 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:23,902 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:23,903 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:23,904 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:24,062 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:24,062 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:24,063 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:24,064 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:24,065 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:24,065 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:24,204 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:24,205 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:24,205 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:24,206 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:24,207 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:24,207 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:24,338 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:24,339 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:24,340 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:24,340 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:24,341 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:24,342 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:24,485 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:24,485 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:24,486 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:24,487 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:24,487 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:24,488 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:24,631 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:24,632 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:24,632 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:24,633 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:24,633 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:24,634 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:24,781 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:24,782 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:24,782 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:24,783 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:24,783 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:24,784 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:24,912 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:24,913 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:24,913 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:24,914 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:24,914 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:24,915 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:25,062 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:25,063 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:25,064 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:25,064 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:25,065 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:25,066 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:25,239 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:25,239 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:25,240 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:25,240 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:25,241 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:25,242 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:25,432 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:25,433 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:25,434 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:25,434 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:25,435 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:25,436 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:25,590 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:25,591 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:25,592 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:25,592 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:25,593 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:25,593 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:25,728 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:25,729 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:25,729 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:25,730 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:25,730 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:25,731 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:25,858 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:25,859 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:25,859 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:25,860 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:25,861 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:25,861 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:25,999 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:26,000 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:26,000 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:26,001 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:26,001 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:26,002 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:26,144 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:26,145 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:26,145 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:26,146 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:26,147 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:26,147 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:26,289 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:26,290 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:26,291 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:26,291 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:26,292 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:26,293 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:26,435 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:26,436 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:26,436 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:26,437 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:26,437 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:26,438 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:26,567 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:26,567 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:26,568 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:26,568 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:26,569 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:26,569 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:26,698 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:26,699 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:26,699 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:26,700 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:26,700 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:26,701 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:26,847 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:26,848 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:26,849 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:26,849 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:26,850 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:26,851 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:26,998 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:26,999 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:26,999 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:27,000 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:27,000 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:27,001 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:27,130 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:27,130 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:27,131 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:27,131 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:27,132 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:27,133 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:27,263 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:27,264 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:27,264 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:27,265 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:27,265 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:27,266 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:27,418 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:27,418 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:27,419 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:27,419 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:27,420 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:27,421 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:27,551 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:27,552 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:27,552 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:27,553 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:27,554 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:27,554 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:27,702 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:27,703 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:27,703 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:27,704 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:27,704 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:27,705 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:27,842 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:27,842 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:27,843 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:27,843 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:27,844 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:27,844 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:27,991 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:27,992 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:27,993 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:27,993 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:27,994 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:27,994 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:28,136 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:28,137 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:28,138 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:28,138 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:28,139 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:28,140 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:28,273 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:28,274 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:28,275 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:28,275 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:28,276 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:28,276 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:28,427 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:28,428 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:28,428 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:28,429 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:28,429 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:28,430 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:28,564 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:28,564 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:28,565 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:28,566 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:28,567 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:28,567 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:28,719 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:28,720 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:28,721 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:28,721 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:28,722 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:28,722 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:28,884 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:28,884 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:28,885 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:28,886 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:28,886 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:28,887 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:29,021 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:29,022 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:29,023 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:29,024 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:29,024 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:29,025 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:29,165 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:29,166 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:29,167 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:29,167 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:29,168 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:29,168 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:29,310 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:29,311 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:29,311 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:29,312 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:29,313 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:29,313 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:29,463 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:29,464 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:29,464 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:29,465 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:29,466 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:29,466 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:29,618 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:29,618 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:29,619 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:29,619 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:29,620 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:29,621 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:29,774 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:29,775 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:29,776 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:29,777 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:29,777 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:29,778 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:29,931 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:29,932 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:29,932 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:29,933 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:29,933 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:29,934 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:30,071 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:30,072 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:30,073 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:30,073 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:30,074 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:30,075 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:30,211 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:30,212 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:30,212 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:30,213 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:30,214 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:30,214 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:30,353 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:30,354 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:30,354 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:30,355 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:30,355 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:30,356 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:30,501 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:30,502 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:30,503 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:30,504 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:30,504 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:30,505 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:30,644 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:30,644 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:30,645 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:30,646 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:30,646 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:30,647 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:30,784 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:30,785 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:30,785 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:30,786 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:30,787 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:30,787 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:30,944 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:30,944 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:30,945 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:30,945 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:30,946 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:30,946 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:31,085 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:31,085 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:31,086 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:31,087 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:31,087 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:31,088 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:31,228 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:31,229 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:31,230 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:31,230 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:31,231 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:31,232 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:31,390 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:31,391 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:31,391 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:31,392 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:31,393 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:31,394 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:31,543 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:31,544 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:31,544 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:31,545 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:31,545 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:31,546 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:31,704 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:31,705 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:31,706 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:31,707 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:31,708 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:31,708 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:31,866 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:31,867 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:31,867 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:31,868 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:31,869 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:31,869 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:32,024 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:32,025 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:32,025 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:32,026 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:32,027 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:32,027 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:32,185 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:32,186 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:32,187 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:32,188 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:32,188 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:32,189 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:32,349 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:32,350 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:32,351 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:32,351 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:32,352 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:32,353 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:32,506 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:32,507 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:32,508 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:32,508 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:32,509 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:32,510 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:32,666 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:32,667 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:32,667 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:32,668 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:32,669 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:32,669 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:32,815 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:32,815 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:32,816 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:32,816 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:32,817 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:32,818 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:32,989 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:32,990 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:32,990 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:32,991 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:32,991 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:32,992 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:33,149 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:33,150 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:33,150 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:33,151 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:33,152 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:33,152 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:33,316 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:33,317 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:33,317 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:33,318 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:33,318 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:33,319 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:33,480 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:33,481 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:33,482 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:33,482 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:33,483 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:33,483 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:33,644 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:33,645 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:33,645 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:33,646 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:33,647 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:33,648 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:33,794 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:33,795 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:33,796 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:33,796 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:33,797 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:33,797 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:33,943 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:33,944 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:33,944 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:33,945 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:33,945 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:33,946 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:34,111 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:34,112 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:34,112 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:34,113 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:34,113 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:34,114 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:34,268 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:34,269 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:34,269 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:34,270 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:34,270 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:34,271 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:34,432 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:34,433 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:34,433 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:34,434 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:34,435 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:34,435 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:34,597 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:34,598 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:34,598 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:34,599 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:34,600 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:34,600 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:34,830 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:34,831 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:34,832 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:34,834 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:34,835 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:34,836 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:35,073 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:35,074 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:35,075 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:35,076 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:35,077 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:35,077 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:35,244 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:35,244 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:35,245 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:35,245 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:35,246 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:35,247 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:35,408 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:35,409 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:35,410 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:35,410 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:35,411 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:35,412 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:35,578 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:35,579 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:35,579 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:35,580 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:35,581 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:35,581 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:35,731 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:35,732 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:35,733 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:35,733 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:35,734 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:35,734 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:35,894 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:35,895 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:35,896 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:35,897 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:35,897 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:35,898 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:36,046 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:36,047 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:36,047 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:36,048 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:36,049 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:36,049 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:36,203 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:36,204 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:36,205 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:36,205 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:36,206 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:36,207 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:36,376 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:36,377 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:36,377 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:36,378 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:36,379 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:36,379 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:36,547 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:36,548 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:36,548 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:36,549 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:36,550 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:36,550 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:36,711 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:36,711 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:36,712 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:36,713 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:36,713 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:36,714 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:36,866 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:36,866 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:36,867 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:36,868 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:36,868 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:36,869 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:37,023 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:37,024 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:37,025 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:37,026 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:37,026 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:37,027 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:37,187 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:37,187 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:37,188 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:37,188 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:37,189 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:37,190 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:37,348 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:37,349 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:37,349 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:37,350 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:37,351 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:37,351 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:37,514 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:37,515 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:37,516 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:37,516 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:37,517 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:37,518 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:37,670 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:37,671 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:37,671 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:37,672 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:37,673 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:37,673 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:37,839 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:37,839 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:37,840 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:37,840 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:37,841 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:37,842 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:37,998 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:37,999 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:37,999 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:38,000 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:38,000 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:38,001 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:38,171 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:38,172 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:38,173 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:38,173 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:38,174 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:38,174 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:38,346 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:38,346 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:38,347 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:38,348 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:38,349 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:38,350 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:38,508 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:38,508 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:38,509 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:38,509 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:38,510 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:38,511 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:38,669 - __main__ - DEBUG - Shape of reversed_position_input torch.Size([16, 1])\n",
      "2025-03-18 15:03:38,670 - __main__ - INFO - reversed_position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:38,671 - __main__ - INFO - reversed_position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:38,671 - __main__ - INFO - position_input_ids shape: torch.Size([16, 1])\n",
      "2025-03-18 15:03:38,672 - __main__ - INFO - position_embeddings shape: torch.Size([16, 1, 1024])\n",
      "2025-03-18 15:03:38,673 - __main__ - DEBUG - decoder_inputs_embeds shape: torch.Size([16, 1, 1024])\n"
     ]
    }
   ],
   "source": [
    "generated_ids = model.generate(\n",
    "              input_ids = batch[\"input_ids\"],\n",
    "              attention_mask = batch[\"attention_mask\"],\n",
    "              target_len = batch[\"target_len\"],\n",
    "              **model.config.task_specific_params[\"summarization\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1024])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"input_ids\"].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
